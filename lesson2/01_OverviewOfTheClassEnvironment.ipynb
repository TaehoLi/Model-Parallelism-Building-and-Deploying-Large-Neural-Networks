{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGBzfhMn0s_f"
   },
   "source": [
    "<img src=\"./images/DLI_Header.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AyzN3JF0s_m"
   },
   "source": [
    "# 1. 클래스 환경 개요\n",
    "\n",
    "이 섹션에서는 클래스 환경에 대한 개요와 NVIDIA의 GPU를 모니터링하는 nvidia-smi 도구를 사용한 실험을 진행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OBUtbsJ0s_o"
   },
   "source": [
    "## 목표\n",
    "\n",
    "이번 실습의 목표는 다음과 같습니다.\n",
    "* 클래스에서 활용하는 하드웨어 구성 이해\n",
    "* NVIDIA GPU를 모니터링하기 위한 기본 명령어 이해\n",
    "* 다른 리소스를 할당하는 간단한 테스트 스크립트 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zhAmi-w0s_p"
   },
   "source": [
    "# 하드웨어 개요\n",
    "\n",
    "이 클래스는 하드웨어 리소스를 제공하고 있습니다. 사용 가능한 리소스를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPqeAdqb0s_q"
   },
   "source": [
    "### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0PmSBltn0s_r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:                    x86_64\n",
      "CPU op-mode(s):                  32-bit, 64-bit\n",
      "Byte Order:                      Little Endian\n",
      "Address sizes:                   46 bits physical, 48 bits virtual\n",
      "CPU(s):                          32\n",
      "On-line CPU(s) list:             0-31\n",
      "Thread(s) per core:              2\n",
      "Core(s) per socket:              16\n",
      "Socket(s):                       1\n",
      "NUMA node(s):                    1\n",
      "Vendor ID:                       GenuineIntel\n",
      "CPU family:                      6\n",
      "Model:                           79\n",
      "Model name:                      Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\n",
      "Stepping:                        1\n",
      "CPU MHz:                         2703.664\n",
      "CPU max MHz:                     3000.0000\n",
      "CPU min MHz:                     1200.0000\n",
      "BogoMIPS:                        4600.03\n",
      "Hypervisor vendor:               Xen\n",
      "Virtualization type:             full\n",
      "L1d cache:                       512 KiB\n",
      "L1i cache:                       512 KiB\n",
      "L2 cache:                        4 MiB\n",
      "L3 cache:                        45 MiB\n",
      "NUMA node0 CPU(s):               0-31\n",
      "Vulnerability Itlb multihit:     KVM: Vulnerable\n",
      "Vulnerability L1tf:              Mitigation; PTE Inversion\n",
      "Vulnerability Mds:               Vulnerable: Clear CPU buffers attempted, no mic\n",
      "                                 rocode; SMT Host state unknown\n",
      "Vulnerability Meltdown:          Mitigation; PTI\n",
      "Vulnerability Spec store bypass: Vulnerable\n",
      "Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user\n",
      "                                  pointer sanitization\n",
      "Vulnerability Spectre v2:        Mitigation; Full generic retpoline, STIBP disab\n",
      "                                 led, RSB filling\n",
      "Vulnerability Srbds:             Not affected\n",
      "Vulnerability Tsx async abort:   Vulnerable: Clear CPU buffers attempted, no mic\n",
      "                                 rocode; SMT Host state unknown\n",
      "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtr\n",
      "                                 r pge mca cmov pat pse36 clflush mmx fxsr sse s\n",
      "                                 se2 ht syscall nx pdpe1gb rdtscp lm constant_ts\n",
      "                                 c rep_good nopl xtopology nonstop_tsc cpuid ape\n",
      "                                 rfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_\n",
      "                                 1 sse4_2 x2apic movbe popcnt tsc_deadline_timer\n",
      "                                  aes xsave avx f16c rdrand hypervisor lahf_lm a\n",
      "                                 bm 3dnowprefetch cpuid_fault invpcid_single pti\n",
      "                                  fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid \n",
      "                                 rtm rdseed adx xsaveopt\n"
     ]
    }
   ],
   "source": [
    "! lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZkQu0aqS0s_t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu cores\t: 16\n"
     ]
    }
   ],
   "source": [
    "# Check the number of CPU cores\n",
    "!grep 'cpu cores' /proc/cpuinfo | uniq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wz3IEJmO0s_v"
   },
   "source": [
    "### 가능한 GPUs 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QbMxtXIV0s_w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 28 06:59:12 2025       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1B.0 Off |                    0 |\n",
      "| N/A   31C    P0    38W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   29C    P0    36W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:00:1D.0 Off |                    0 |\n",
      "| N/A   29C    P0    38W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   29C    P0    38W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check available GPUs\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82Ra4hHG0s_y"
   },
   "source": [
    "### 인터커넥트 토폴로지 \n",
    "\n",
    "<img style=\"float: right;\" src=\"images/nvlink.png\" width=\"200\"/>\n",
    "\n",
    "멀티 GPU 시스템 구성에서는 빠르고 확장 가능한 상호 연결이 필요한 반면에 표준 PCIe 익스프레스 대역폭은 제한되어 있습니다. \n",
    "\n",
    "[NVIDIA NVLink 기술](https://www.nvidia.com/en-us/data-center/nvlink/)은 멀티 GPU 시스템 구성을 위한 더 높은 대역폭, 더 많은 링크 및 향상된 확장성을 제공하는 GPU 간 직접 상호 연결을 제공합니다.\n",
    "\n",
    "사용 가능한 인터커넥트 토폴로지를 확인하려면 `nvidia-smi topo --matrix` 를 사용합니다. 이번 교육 과정에서 우리는 GPU 기기당 4개의 링크를 받아야 합니다.\n",
    "\n",
    "```\n",
    "        GPU0    GPU1    GPU2    GPU3    CPU Affinity    NUMA Affinity\n",
    "GPU0     X      NV1     NV1     NV2     0-31            N/A\n",
    "GPU1    NV1      X      NV2     NV1     0-31            N/A\n",
    "GPU2    NV1     NV2      X      NV2     0-31            N/A\n",
    "GPU3    NV2     NV1     NV2      X      0-31            N/A\n",
    "\n",
    "Where X= Self and NV# = Connection traversing a bonded set of # NVLinks\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NUOATllT0s_0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\u001b[4mGPU0\tGPU1\tGPU2\tGPU3\tCPU Affinity\tNUMA Affinity\u001b[0m\n",
      "GPU0\t X \tNV1\tNV1\tNV2\t0-31\t\tN/A\n",
      "GPU1\tNV1\t X \tNV2\tNV1\t0-31\t\tN/A\n",
      "GPU2\tNV1\tNV2\t X \tNV2\t0-31\t\tN/A\n",
      "GPU3\tNV2\tNV1\tNV2\t X \t0-31\t\tN/A\n",
      "\n",
      "Legend:\n",
      "\n",
      "  X    = Self\n",
      "  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)\n",
      "  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node\n",
      "  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)\n",
      "  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)\n",
      "  PIX  = Connection traversing at most a single PCIe bridge\n",
      "  NV#  = Connection traversing a bonded set of # NVLinks\n"
     ]
    }
   ],
   "source": [
    "# Check Interconnect Topology \n",
    "! nvidia-smi topo --matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXGj1VwQ0s_0"
   },
   "source": [
    "`nvidia-smi nvlink --status` 명령어를 사용하여 NVLink 상태 및 기능을 확인할 수도 있습니다. 장치당 유사한 출력이 있어야 합니다.\n",
    "\n",
    "```\n",
    "GPU 0: Tesla V100-SXM2-16GB \n",
    "\t Link 0: 25.781 GB/s\n",
    "\t Link 1: 25.781 GB/s\n",
    "\t Link 2: 25.781 GB/s\n",
    "\t Link 3: 25.781 GB/s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ux06AbM70s_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-759b273c-9617-dbe0-6fc1-e185f518e0eb)\n",
      "\t Link 0: 25.781 GB/s\n",
      "\t Link 1: 25.781 GB/s\n",
      "\t Link 2: 25.781 GB/s\n",
      "\t Link 3: 25.781 GB/s\n",
      "GPU 1: Tesla V100-SXM2-16GB (UUID: GPU-f1f92348-9fdd-5e49-c4f4-add72ac06f4d)\n",
      "\t Link 0: 25.781 GB/s\n",
      "\t Link 1: 25.781 GB/s\n",
      "\t Link 2: 25.781 GB/s\n",
      "\t Link 3: 25.781 GB/s\n",
      "GPU 2: Tesla V100-SXM2-16GB (UUID: GPU-5489d3e6-d0d1-ec98-3237-06c066b5e680)\n",
      "\t Link 0: 25.781 GB/s\n",
      "\t Link 1: 25.781 GB/s\n",
      "\t Link 2: 25.781 GB/s\n",
      "\t Link 3: 25.781 GB/s\n",
      "\t Link 4: 25.781 GB/s\n",
      "GPU 3: Tesla V100-SXM2-16GB (UUID: GPU-09d5cb00-3cad-cc4c-c455-6a999ee69d28)\n",
      "\t Link 0: 25.781 GB/s\n",
      "\t Link 1: 25.781 GB/s\n",
      "\t Link 2: 25.781 GB/s\n",
      "\t Link 3: 25.781 GB/s\n",
      "\t Link 4: 25.781 GB/s\n"
     ]
    }
   ],
   "source": [
    "# Check nvlink status\n",
    "! nvidia-smi nvlink --status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9VTqRm60s_2"
   },
   "source": [
    "### 연결성 테스트하기 \n",
    "\n",
    "    `git clone --depth 1 --branch v11.2 https://github.com/NVIDIA/cuda-samples.git`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZILkqT130s_3"
   },
   "source": [
    "NVIDIA는 **p2pBandwidthLatencyTest** 애플리케이션을 제공합니다. NVLinks를 활성화/비활성화하면서 대역폭 및 지연시간을 계산하여 GPU 쌍 간에 CUDA P2P(Peer-To-Peer) 데이터 전송을 보여주는 테스트입니다. 이 도구는 CUDA 개발자에서 제공하는  [cuda-samples](https://github.com/NVIDIA/cuda-samples.git) 코드 샘플의 일부입니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wh-LJxrc0s_4"
   },
   "outputs": [],
   "source": [
    "!chmod 770 ./cuda-samples/bin/x86_64/linux/release/p2pBandwidthLatencyTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tasIftH90s_4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[P2P (Peer-to-Peer) GPU Bandwidth Latency Test]\n",
      "Device: 0, Tesla V100-SXM2-16GB, pciBusID: 0, pciDeviceID: 1b, pciDomainID:0\n",
      "Device: 1, Tesla V100-SXM2-16GB, pciBusID: 0, pciDeviceID: 1c, pciDomainID:0\n",
      "Device: 2, Tesla V100-SXM2-16GB, pciBusID: 0, pciDeviceID: 1d, pciDomainID:0\n",
      "Device: 3, Tesla V100-SXM2-16GB, pciBusID: 0, pciDeviceID: 1e, pciDomainID:0\n",
      "Device=0 CAN Access Peer Device=1\n",
      "Device=0 CAN Access Peer Device=2\n",
      "Device=0 CAN Access Peer Device=3\n",
      "Device=1 CAN Access Peer Device=0\n",
      "Device=1 CAN Access Peer Device=2\n",
      "Device=1 CAN Access Peer Device=3\n",
      "Device=2 CAN Access Peer Device=0\n",
      "Device=2 CAN Access Peer Device=1\n",
      "Device=2 CAN Access Peer Device=3\n",
      "Device=3 CAN Access Peer Device=0\n",
      "Device=3 CAN Access Peer Device=1\n",
      "Device=3 CAN Access Peer Device=2\n",
      "\n",
      "***NOTE: In case a device doesn't have P2P access to other one, it falls back to normal memcopy procedure.\n",
      "So you can see lesser Bandwidth (GB/s) and unstable Latency (us) in those cases.\n",
      "\n",
      "P2P Connectivity Matrix\n",
      "     D\\D     0     1     2     3\n",
      "     0\t     1     1     1     1\n",
      "     1\t     1     1     1     1\n",
      "     2\t     1     1     1     1\n",
      "     3\t     1     1     1     1\n",
      "Unidirectional P2P=Disabled Bandwidth Matrix (GB/s)\n",
      "   D\\D     0      1      2      3 \n",
      "     0 777.75   9.42  10.35  10.53 \n",
      "     1   9.41 779.69  10.35  10.53 \n",
      "     2  10.50  10.49 778.91   9.44 \n",
      "     3  10.51  10.50   9.47 779.69 \n",
      "Unidirectional P2P=Enabled Bandwidth (P2P Writes) Matrix (GB/s)\n",
      "   D\\D     0      1      2      3 \n",
      "     0 777.75  24.25  24.25  48.48 \n",
      "     1  24.25 779.69  48.48  24.25 \n",
      "     2  24.25  48.48 778.53  48.48 \n",
      "     3  48.48  24.25  48.48 779.30 \n",
      "Bidirectional P2P=Disabled Bandwidth Matrix (GB/s)\n",
      "   D\\D     0      1      2      3 \n",
      "     0 779.50   9.43  14.35  14.45 \n",
      "     1   9.65 780.47  14.11  14.19 \n",
      "     2  14.39  14.19 779.69   9.42 \n",
      "     3  14.43  14.22   9.46 778.53 \n",
      "Bidirectional P2P=Enabled Bandwidth Matrix (GB/s)\n",
      "   D\\D     0      1      2      3 \n",
      "     0 780.08  48.49  48.49  96.89 \n",
      "     1  48.49 779.50  96.91  48.49 \n",
      "     2  48.49  96.91 779.11  96.89 \n",
      "     3  96.90  48.49  96.91 778.91 \n",
      "P2P=Disabled Latency Matrix (us)\n",
      "   GPU     0      1      2      3 \n",
      "     0   1.77  17.50  17.60  17.70 \n",
      "     1  17.73   1.74  17.62  17.60 \n",
      "     2  17.46  17.59   1.73  17.58 \n",
      "     3  17.50  17.61  17.60   1.71 \n",
      "\n",
      "   CPU     0      1      2      3 \n",
      "     0   2.89   8.11   7.98   8.12 \n",
      "     1   7.93   2.82   7.89   7.88 \n",
      "     2   7.88   7.87   2.84   7.92 \n",
      "     3   8.03   7.97   7.93   2.87 \n",
      "P2P=Enabled Latency (P2P Writes) Matrix (us)\n",
      "   GPU     0      1      2      3 \n",
      "     0   1.77   2.01   2.02   2.00 \n",
      "     1   2.00   1.74   2.00   2.00 \n",
      "     2   2.00   1.99   1.73   2.00 \n",
      "     3   2.01   2.00   1.99   1.72 \n",
      "\n",
      "   CPU     0      1      2      3 \n",
      "     0   3.26   2.23   2.28   2.32 \n",
      "     1   2.40   2.94   2.61   2.38 \n",
      "     2   2.36   2.27   2.81   2.18 \n",
      "     3   2.38   2.35   2.40   3.35 \n",
      "\n",
      "NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.\n"
     ]
    }
   ],
   "source": [
    "!./cuda-samples/bin/x86_64/linux/release/p2pBandwidthLatencyTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FeKbxh80s_5"
   },
   "source": [
    "<h2 style=\"color:green;\">축하합니다!</h2>\n",
    "\n",
    "과정의 이번 섹션에 대한 정보를 검토완료했으며 다음 실습을 시작할 준비가 되었습니다.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6I2H3340s_6"
   },
   "source": [
    "[HuggingFace로 GPT-J 6b 모델 추론하기](02_HFRunInferenceOfTheGPT-J.ipynb)로 이동합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3_01_OverviewOfTheClassEnvironment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
