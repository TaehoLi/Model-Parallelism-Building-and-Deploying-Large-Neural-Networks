{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Ij5iDr6o2S-"
   },
   "source": [
    "<img src=\"./images/DLI_Header.png\" style=\"width: 400px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiGFqOdDo2TB"
   },
   "source": [
    "# 4. 분산 학습 최적화\n",
    "\n",
    "이번 노트북에서는 [Megatron-LM](https://github.com/NVIDIA/Megatron-LM) 를 활용하여 GPT 사전 훈련 성능을 정량화하는 방법에 대해 배우고 혼합 정밀도, 그래디언트 누적 및 활성화 체크포인팅과 같은 최적화 기술을 살펴보겠습니다.\n",
    "\n",
    "## 목표\n",
    "\n",
    "이번 노트북의 목표는 다음과 같습니다:\n",
    "* 자동 혼합 정밀도(AMP, Automatic Mixed Precision) 및 활성화 체크포인팅(Activation Checkpointing)을 사용하여 Megatron-LM 스크립트의 멀티 노드 학습을 최적화합니다. \n",
    "* 학습 성과를 계산하는 방법을 이해합니다.\n",
    "\n",
    "\n",
    "**[4.1 혼합 정밀도 학습](#1.1-The-hardware-overview)<br>**\n",
    "**[4.2 활성화 체크포인팅 ](#1.1-The-hardware-overview)<br>**\n",
    "**[4.3 그래디언트 누적](#1.1-The-hardware-overview)<br>**\n",
    "**[4.4 학습 성능](#4.4-Compute-The-Training-Performance)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[4.4.1 매개 변수의 숫자를 연산하기](#1.1.1-Check-The-Available-CPUs)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[4.4.2 연습: 우리 모델의 매개 변수 숫자를 연산하기](#1.1.2-Check-The-Available-GPUs)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[4.4.3 GPU 당 이론 피크 FLOP/초 연산하기](#1.1.3-Check-The-Interconnect-Topology)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[4.4.4 학습 기간 / 에포크를 추정하기](#1.1.3-Check-The-Interconnect-Topology)<br>\n",
    "\n",
    "### 이전 실행/보류 중인 작업을 취소합니다.\n",
    "\n",
    "다음으로 이동하기 전에 SLURM 대기열에서 아직 실행 중이거나 대기 중인 작업이 없는지 확인하십시오. 다음 셀을 실행하여 SLURM 작업 대기열을 확인합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PX96s88to2TC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n"
     ]
    }
   ],
   "source": [
    "# Check the SLURM jobs queue \n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6T0vnNZ2o2TD"
   },
   "source": [
    "아직 실행 중이거나 보류 중인 작업이 있는 경우 다음 셀을 실행하고 `scancel` 명령을 사용하여 모든 사용자의 작업을 취소합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-mc1fojJo2TD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n"
     ]
    }
   ],
   "source": [
    "# Cancel admin user jobs\n",
    "! scancel -u $USER\n",
    "\n",
    "# Check again the SLURM jobs queue (should be either empty, or the status TS column should be CG)\n",
    "! squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtyIpvOKo2TD"
   },
   "source": [
    "---\n",
    "# 4.1 혼합 정밀도 트레이닝 \n",
    "\n",
    "<img src=\"images/AMP.png\" width=\"700\"/>\n",
    "\n",
    "**Automatic Mixed Precision (AMP)** 는 수학적 연산을 실행할 때 서로 다른 수치 정밀도를 사용할 수 있습니다. 네트워크의 중요한 부분에서 단일 정밀도를 유지하면서 필요한 메모리를 줄이는 반-정밀도 형식으로 몇몇 작업을 수행합니다.\n",
    "\n",
    "Automatic Mixed Precision (자동 혼합 정밀도)을 사용한 학습은 Volta 아키텍처(Volta, Turing, Ampere 및 그 이후 아키텍처)부터 사용할 수 있는 NVIDIA GPU 의 Tensor Core가 제공하는 하드웨어 가속화를 활용합니다. AMP 학습에 대한 자세한 내용은 [혼합 정밀도 훈련 설명서](https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html)를 참조하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tz7j2UHo2TE"
   },
   "source": [
    "이전 노트북에서는 베이스라인 실행에 대해 혼합 정밀도 트레이닝이 활성화되지 않았습니다. GPU Kernel view에서 세부 정보를 볼 수 있습니다. \n",
    "\n",
    "<img src=\"images/profiling3.png\" width=\"650\"/>\n",
    "\n",
    "overview 탭 ( 3.4.2 Tensorboard with Pytorch Profiler 섹션의 그림에도 표시)에서 실행한 베이스라인 실행의 성능 권장 사항에 따르면 전체 시간의 27%를 차지하는 커널은 Tensor Core 적격 오퍼레이터에 의해 실행됩니다. FP16으로 자동 혼합 정밀도(AMP)를 활성화하면 연산 속도를 높일 수 있습니다.\n",
    "\n",
    "혼합 정밀도에서 Megatron-LM 사전 훈련을 실행하려면 GPT_ARGS에 `--fp16` 인수를 추가하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fk9Hj-6ao2TE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /dli/code/pretrain_gpt_2Node4GPU_increase_MBS_fp16.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile /dli/code/pretrain_gpt_2Node4GPU_increase_MBS_fp16.sh\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=dli_2nodes\n",
    "#SBATCH --nodes=2\n",
    "#SBATCH --ntasks-per-node=1       \n",
    "#SBATCH --cpus-per-task=32 ### Number of threads per task (OMP threads)\n",
    "#SBATCH -o /dli/megatron/logs/%j.out\n",
    "#SBATCH -e /dli/megatron/logs/%j.err\n",
    "\n",
    "set -x -e\n",
    "\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "\n",
    "# Distributed training args\n",
    "NNODES=2\n",
    "GPUS_PER_NODE=2\n",
    "TP_SIZE=1\n",
    "PP_SIZE=1 \n",
    "\n",
    "# SLURM args\n",
    "MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)\n",
    "MASTER_PORT=6000\n",
    "\n",
    "# Distributed training \n",
    "MICRO_BATCH_SIZE=4      \n",
    "GLOBAL_BATCH_SIZE=16    \n",
    "\n",
    "# Model architecture \n",
    "NLAYERS=12\n",
    "NHIDDEN=768\n",
    "NHEADS=32\n",
    "SEQ_LEN=1024\n",
    "VOCAB_SIZE=50257\n",
    "\n",
    "# Data Paths\n",
    "DATA_OUTPUT_PATH=/dli/megatron/checkpoints/test\n",
    "CHECKPOINT_PATH=/dli/megatron/checkpoints\n",
    "TENSORBOARD_PATH=/dli/megatron/tensorboard\n",
    "LOGS_PATH=/dli/megatron/logs\n",
    "VOCAB_FILE=/dli/data/GPT-2_assets/gpt2-vocab.json\n",
    "MERGE_FILE=/dli/data/GPT-2_assets/gpt2-merges.txt\n",
    "DATA_PATH=/dli/data/GPT-2_assets/my-gpt2_text_document\n",
    "\n",
    "NAME=\"log_2Nodes4GPUS_increase_GBS_fp16\"        \n",
    "\n",
    "OPTIMIZER_ARGS=\" \\\n",
    "            --optimizer adam \\\n",
    "            --adam-beta1 0.9 \\\n",
    "            --adam-beta2 0.95 \\\n",
    "            --adam-eps 1e-8 \\\n",
    "            --lr 6e-5 \\\n",
    "            --min-lr 6e-6 \\\n",
    "            --lr-decay-style cosine \\\n",
    "            --lr-decay-iters 800 \\\n",
    "            --lr-warmup-fraction .01 \\\n",
    "            --clip-grad 1.0 \\\n",
    "            --weight-decay 1e-1 \\\n",
    "            --exit-duration-in-mins 1190 \\\n",
    "              \"\n",
    "\n",
    "GPT_ARGS=\" \\\n",
    "            --num-layers $NLAYERS \\\n",
    "            --hidden-size $NHIDDEN \\\n",
    "            --num-attention-heads $NHEADS \\\n",
    "            --seq-length $SEQ_LEN \\\n",
    "            --max-position-embeddings $SEQ_LEN \\\n",
    "            --micro-batch-size $MICRO_BATCH_SIZE \\\n",
    "            --global-batch-size $GLOBAL_BATCH_SIZE \\\n",
    "            --train-iters 100 \\\n",
    "            --vocab-file $VOCAB_FILE \\\n",
    "            --merge-file $MERGE_FILE \\\n",
    "            --init-method-std 0.006 \\\n",
    "            --fp16 \\\n",
    "            $OPTIMIZER_ARGS \\\n",
    "            \"\n",
    "\n",
    "OUTPUT_ARGS=\" \\\n",
    "            --log-interval 10 \\\n",
    "            --save-interval 300 \\\n",
    "            --eval-interval 1000 \\\n",
    "            --eval-iters 10 \\\n",
    "            --tensorboard-dir $TENSORBOARD_PATH \\\n",
    "            --tensorboard-queue-size 1 \\\n",
    "            --log-timers-to-tensorboard \\\n",
    "            --log-batch-size-to-tensorboard \\\n",
    "            --log-validation-ppl-to-tensorboard \\\n",
    "            --profile-execution True \\\n",
    "            --profile-name fp16 \\\n",
    "            \"\n",
    "\n",
    "export LAUNCHER=\"python -u -m torch.distributed.launch \\\n",
    "             --nproc_per_node $GPUS_PER_NODE \\\n",
    "             --nnodes $NNODES \\\n",
    "             --master_addr $MASTER_ADDR \\\n",
    "             --master_port $MASTER_PORT \\\n",
    "             \"\n",
    "\n",
    "export CMD=\" \\\n",
    "             /dli/megatron/Megatron-LM/pretrain_gpt.py \\\n",
    "             --tensor-model-parallel-size $TP_SIZE \\\n",
    "             --pipeline-model-parallel-size $PP_SIZE \\\n",
    "             $GPT_ARGS \\\n",
    "             $OUTPUT_ARGS \\\n",
    "             --save $CHECKPOINT_PATH \\\n",
    "             --data-path $DATA_PATH \\\n",
    "             --data-impl mmap \\\n",
    "             --split 949,50,1 \\\n",
    "             --distributed-backend nccl \\\n",
    "           \"\n",
    "\n",
    "clear; srun --jobid $SLURM_JOBID bash -c 'NCCL_DEBUG=INFO  $LAUNCHER --node_rank $SLURM_PROCID $CMD' 2>&1 | tee -a $LOGS_PATH/$NAME.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvsDnVnno2TF"
   },
   "source": [
    "이제 이전에 작업해 둔 sbatch 스크립트[pretrain_gpt_2Node4GPU_increase_MBS_fp16.sh](./code/pretrain_gpt_2Node4GPU_increase_MBS_fp16.sh) 를 제출하겠습니다. `squeue` 명령어를 사용하여 SLURM 대기열을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AY9oALt-o2TG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 13\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "                13  slurmpar dli_2nod    admin  R       0:00      2 slurmnode[1-2]\n"
     ]
    }
   ],
   "source": [
    "# submit the 2 nodes jobs\n",
    "! sbatch /dli/code/pretrain_gpt_2Node4GPU_increase_MBS_fp16.sh\n",
    "\n",
    "# Check the SLURM queue\n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tw69AwOho2TH"
   },
   "source": [
    "Megatron GPT3 사전 훈련의 성능을 이해하기 위해, 우리는 실행 중에 생성된 로그를 확인할 수 있습니다.\n",
    "\n",
    "먼저 생성된 [로그](./megatron/logs/log_2Nodes4GPUS_increase_GBS_fp16.txt) 를 사용하여 실행의 world size를 확인합니다. 아래 부분을 확인해 보아야 합니다:\n",
    "\n",
    "```\n",
    "    using world size: 4, data-parallel-size: 4, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 \n",
    "    using torch.float16 for parameters ...\n",
    "```\n",
    "\n",
    "fp16 모드에서 실행할 때 `torch.float16 for parameters`라는 메시지가 나타납니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1I_0TYH_o2TH"
   },
   "source": [
    "잠시 후 학습 성과를 확인하고 강사와 함께 논의해 봅니다. 처음으로 Megatron-LM을 실행하는 경우, 코드를 컴파일하는 데 약 6분이 소요됩니다. 그 때까지는 GPU 활동을 볼 수 없을 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "E5TBSlNRo2TH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " iteration       10/     100 | consumed samples:          160 | elapsed time per iteration (ms): 509.6 | learning rate: 0.000E+00 | global batch size:    16 | loss scale: 8388608.0 | number of skipped iterations:  10 | number of nan iterations:   0 |\n",
      " iteration       20/     100 | consumed samples:          320 | elapsed time per iteration (ms): 311.9 | learning rate: 3.000E-05 | global batch size:    16 | lm loss: 1.070710E+01 | loss scale: 131072.0 | grad norm: 4.466 | number of skipped iterations:   6 | number of nan iterations:   0 |\n",
      " iteration       30/     100 | consumed samples:          480 | elapsed time per iteration (ms): 315.8 | learning rate: 5.999E-05 | global batch size:    16 | lm loss: 1.021160E+01 | loss scale: 65536.0 | grad norm: 2.516 | number of skipped iterations:   1 | number of nan iterations:   0 |\n",
      " iteration       40/     100 | consumed samples:          640 | elapsed time per iteration (ms): 318.3 | learning rate: 5.995E-05 | global batch size:    16 | lm loss: 9.778532E+00 | loss scale: 65536.0 | grad norm: 2.661 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       50/     100 | consumed samples:          800 | elapsed time per iteration (ms): 316.3 | learning rate: 5.987E-05 | global batch size:    16 | lm loss: 9.318542E+00 | loss scale: 65536.0 | grad norm: 2.334 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       60/     100 | consumed samples:          960 | elapsed time per iteration (ms): 569.7 | learning rate: 5.974E-05 | global batch size:    16 | lm loss: 8.886666E+00 | loss scale: 65536.0 | grad norm: 2.431 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       70/     100 | consumed samples:         1120 | elapsed time per iteration (ms): 315.1 | learning rate: 5.957E-05 | global batch size:    16 | lm loss: 8.548711E+00 | loss scale: 65536.0 | grad norm: 2.445 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       80/     100 | consumed samples:         1280 | elapsed time per iteration (ms): 326.3 | learning rate: 5.936E-05 | global batch size:    16 | lm loss: 8.248992E+00 | loss scale: 65536.0 | grad norm: 2.112 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       90/     100 | consumed samples:         1440 | elapsed time per iteration (ms): 322.8 | learning rate: 5.911E-05 | global batch size:    16 | lm loss: 7.973923E+00 | loss scale: 65536.0 | grad norm: 2.116 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration      100/     100 | consumed samples:         1600 | elapsed time per iteration (ms): 313.9 | learning rate: 5.881E-05 | global batch size:    16 | lm loss: 7.699454E+00 | loss scale: 65536.0 | grad norm: 1.845 | number of skipped iterations:   0 | number of nan iterations:   0 |\n"
     ]
    }
   ],
   "source": [
    "! grep elapsed /dli/megatron/logs/log_2Nodes4GPUS_increase_GBS_fp16.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "125Jl7CLo2TH"
   },
   "source": [
    "### Tensorboard - Pytorch Profiler\n",
    "\n",
    "프로파일링은 이전 실행의 Tensorboard 링크 내 `pytorch_profiler` 탭에서 가능합니다. 텐서보드 페이지를 이미 닫은 경우 다음 셀을 실행하여 링크를 다시 생성할 수 있습니다. 링크를 클릭하여 텐서보드를 연 다음 `PYTORCH_PROFILER` 탭으로 이동합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6zp08VDQo2TI"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "const href = window.location.hostname +'/tensorboard/';\n",
       "let a = document.createElement('a');\n",
       "let link = document.createTextNode('Open Tensorboard!');\n",
       "a.appendChild(link);\n",
       "a.href = \"http://\" + href;\n",
       "a.style.color = \"navy\"\n",
       "a.target = \"_blank\"\n",
       "element.append(a);\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%js\n",
    "const href = window.location.hostname +'/tensorboard/';\n",
    "let a = document.createElement('a');\n",
    "let link = document.createTextNode('Open Tensorboard!');\n",
    "a.appendChild(link);\n",
    "a.href = \"http://\" + href;\n",
    "a.style.color = \"navy\"\n",
    "a.target = \"_blank\"\n",
    "element.append(a);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wl9Xgll1o2TI"
   },
   "source": [
    "`run_fp16_gpu0`결과를 보면 GPU 활용도가 감소합니다. GPU 커널 뷰에서 혼합 정밀도를 활성화하면 GPU 연산의 23.6%가 텐서코어로 가속된다는 것을 알 수 있습니다.\n",
    "\n",
    "<img src=\"images/profiling5_AMP.png\" width=\"400\"/>\n",
    "\n",
    "\n",
    "### 메모리는 어떤가요?\n",
    "12G (베이스라인에서 ~10G)의 피크에 따라 메모리 소비가 증가한다는 것을 알 수 있습니다. 이는 일부 모델 가중치가 FP32와 FP16에 모두 저장되고 액티베이션과 그레디언트는 FP16에 저장되기 때문입니다. 따라서 가중치의 메모리 사용량이 증가하는 반면 정방향 및 역방향 패스의 액티베이션 및 그레디언트에 사용되는 메모리는 줄어듭니다. 새 점프를 확대하면 추가 Pytorch 복사 연산 *_to_copy* 가 표시됩니다.\n",
    "\n",
    "<img src=\"images/profiling_FP16_memory.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrrUqk5vo2TI"
   },
   "source": [
    "좋습니다! 다음으로 넘어가기 전에 이전 실행에서 생성된 불필요한 체크포인트를 삭제하여 디스크 공간을 확보해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vy3ZvhBKo2TI"
   },
   "outputs": [],
   "source": [
    "# Clean the checkpoints \n",
    "! rm -rf /dli/megatron/checkpoints/* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BpfvefUuo2TJ"
   },
   "source": [
    "---\n",
    "# 4.2 활성화 체크포인팅\n",
    "\n",
    "\n",
    "<img src=\"images/activation_checkpoiting.png\" width=\"700\" align=\"center\"/>\n",
    "\n",
    "활성화 체크 포인팅은 추가 재계산 비용으로 학습 중에 메모리를 절약할 수 있는 또 다른 기술입니다. 바닐라 포워드, 백워드 패스에서 모든 피쳐 맵은 포워드 패스 동안 계산되고 백워드 단계를 위해 저장됩니다. 활성화 체크포인팅 전략에서는 포워드 패스 중에 일부 중간 결과만 저장합니다 (체크포인트라고 불림). 이러한 체크포인트는 필요할 때 추가 피쳐 맵을 재계산하기 위해 백워드 패스에서 사용됩니다. 체크포인팅에는 사용자가 제공하는 수동 체크포인트 또는 자동 선택을 포함하여 여러 가지 구현 방법이 있습니다.\n",
    "\n",
    "Megatron-LM은 Uniform 및 Block의 두 가지 활성화 체크포인트 방법을 지원합니다.\n",
    "\n",
    "- Uniform: 레이어를 균일하게 그룹으로 나누고 각 그룹의 입력 활성화를 메모리에 저장합니다. \n",
    "- Block: 파이프라인 단계당 설정된 개별 Transformer 레이어 세트의 입력 활성화를 검사합니다.\n",
    "\n",
    "활성화 체크포인팅을 사용하여 Megatron-LM 사전 훈련을 실행하려면 단순히 --activations-checkpoint-method` 인자를 추가하여 GPT_ARGS에서 uniform 또는 block 로 설정하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xb7dorKSo2TJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /dli/code/pretrain_gpt_2Node4GPU_increase_BS_fp16_activation_checkpointing.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile /dli/code/pretrain_gpt_2Node4GPU_increase_BS_fp16_activation_checkpointing.sh\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=dli_2nodes\n",
    "#SBATCH --nodes=2\n",
    "#SBATCH --ntasks-per-node=1       \n",
    "#SBATCH --cpus-per-task=32 ### Number of threads per task (OMP threads)\n",
    "#SBATCH -o /dli/megatron/logs/%j.out\n",
    "#SBATCH -e /dli/megatron/logs/%j.err\n",
    "\n",
    "set -x -e\n",
    "\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "\n",
    "# Distributed training args\n",
    "NNODES=2\n",
    "GPUS_PER_NODE=2\n",
    "TP_SIZE=1\n",
    "PP_SIZE=1 \n",
    "\n",
    "# SLURM args\n",
    "MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)\n",
    "MASTER_PORT=6000\n",
    "\n",
    "# Distributed training \n",
    "MICRO_BATCH_SIZE=4      \n",
    "GLOBAL_BATCH_SIZE=16    \n",
    "\n",
    "# Model architecture \n",
    "NLAYERS=12\n",
    "NHIDDEN=768\n",
    "NHEADS=32\n",
    "SEQ_LEN=1024\n",
    "VOCAB_SIZE=50257\n",
    "\n",
    "# Data Paths\n",
    "DATA_OUTPUT_PATH=/dli/megatron/checkpoints/test\n",
    "CHECKPOINT_PATH=/dli/megatron/checkpoints\n",
    "TENSORBOARD_PATH=/dli/megatron/tensorboard\n",
    "LOGS_PATH=/dli/megatron/logs\n",
    "VOCAB_FILE=/dli/data/GPT-2_assets/gpt2-vocab.json\n",
    "MERGE_FILE=/dli/data/GPT-2_assets/gpt2-merges.txt\n",
    "DATA_PATH=/dli/data/GPT-2_assets/my-gpt2_text_document\n",
    "\n",
    "NAME=\"log_2Nodes4GPUS_increase_GBS_fp16_activation_checkpointing\"        \n",
    "\n",
    "\n",
    "OPTIMIZER_ARGS=\" \\\n",
    "            --optimizer adam \\\n",
    "            --adam-beta1 0.9 \\\n",
    "            --adam-beta2 0.95 \\\n",
    "            --adam-eps 1e-8 \\\n",
    "            --lr 6e-5 \\\n",
    "            --min-lr 6e-6 \\\n",
    "            --lr-decay-style cosine \\\n",
    "            --lr-decay-iters 800 \\\n",
    "            --lr-warmup-fraction .01 \\\n",
    "            --clip-grad 1.0 \\\n",
    "            --weight-decay 1e-1 \\\n",
    "            --exit-duration-in-mins 1190 \\\n",
    "              \"\n",
    "\n",
    "GPT_ARGS=\" \\\n",
    "            --num-layers $NLAYERS \\\n",
    "            --hidden-size $NHIDDEN \\\n",
    "            --num-attention-heads $NHEADS \\\n",
    "            --seq-length $SEQ_LEN \\\n",
    "            --max-position-embeddings $SEQ_LEN \\\n",
    "            --micro-batch-size $MICRO_BATCH_SIZE \\\n",
    "            --global-batch-size $GLOBAL_BATCH_SIZE \\\n",
    "            --train-iters 100 \\\n",
    "            --vocab-file $VOCAB_FILE \\\n",
    "            --merge-file $MERGE_FILE \\\n",
    "            --init-method-std 0.006 \\\n",
    "            --fp16 \\\n",
    "            --activations-checkpoint-method uniform \\\n",
    "            $OPTIMIZER_ARGS \\\n",
    "            \"\n",
    "\n",
    "OUTPUT_ARGS=\" \\\n",
    "            --log-interval 10 \\\n",
    "            --save-interval 300 \\\n",
    "            --eval-interval 1000 \\\n",
    "            --eval-iters 10 \\\n",
    "            --tensorboard-dir $TENSORBOARD_PATH \\\n",
    "            --tensorboard-queue-size 1 \\\n",
    "            --log-timers-to-tensorboard \\\n",
    "            --log-batch-size-to-tensorboard \\\n",
    "            --log-validation-ppl-to-tensorboard \\\n",
    "            --profile-execution True \\\n",
    "            --profile-name  fp16_activation_checkpointing \\\n",
    "            \"\n",
    "\n",
    "export LAUNCHER=\"python -u -m torch.distributed.launch \\\n",
    "             --nproc_per_node $GPUS_PER_NODE \\\n",
    "             --nnodes $NNODES \\\n",
    "             --master_addr $MASTER_ADDR \\\n",
    "             --master_port $MASTER_PORT \\\n",
    "             \"\n",
    "\n",
    "export CMD=\" \\\n",
    "             /dli/megatron/Megatron-LM/pretrain_gpt.py \\\n",
    "             --tensor-model-parallel-size $TP_SIZE \\\n",
    "             --pipeline-model-parallel-size $PP_SIZE \\\n",
    "             $GPT_ARGS \\\n",
    "             $OUTPUT_ARGS \\\n",
    "             --save $CHECKPOINT_PATH \\\n",
    "             --data-path $DATA_PATH \\\n",
    "             --data-impl mmap \\\n",
    "             --split 949,50,1 \\\n",
    "             --distributed-backend nccl \\\n",
    "           \"\n",
    "\n",
    "clear; srun --jobid $SLURM_JOBID bash -c 'NCCL_DEBUG=INFO  $LAUNCHER --node_rank $SLURM_PROCID $CMD' 2>&1 | tee -a $LOGS_PATH/$NAME.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmUaItaAo2TK"
   },
   "source": [
    "이제 이전에 제작한 sbatch 스크립트[pretrain_gpt_2Node4GPU_increase_BS_fp16_activation_checkpointing.sh](/dli/code/pretrain_gpt_2Node4GPU_increase_BS_fp16_activation_checkpoiting.sh) 를 제출합니다. `squeue`명령어를 사용하여 SLURM 대기열을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QxkmWTG2o2TK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 14\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "                14  slurmpar dli_2nod    admin  R       0:00      2 slurmnode[1-2]\n"
     ]
    }
   ],
   "source": [
    "# Submit the 2 nodes jobs\n",
    "! sbatch /dli/code/pretrain_gpt_2Node4GPU_increase_BS_fp16_activation_checkpointing.sh\n",
    "\n",
    "# Check the SLURM queue\n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfZr5wRdo2TK"
   },
   "source": [
    "메가트론 GPT3 사전 훈련의 성능을 이해하기 위해 생성된 [로그](./megatron/logs/log_2Nodes4GPUS_increaseBS_fp16_activation_checkpointing.txt) 를 체크하고 강사와 논의해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Uvrrhbm-o2TK"
   },
   "outputs": [],
   "source": [
    "! grep elapsed /dli/megatron/logs/log_2Nodes4GPUS_increase_GBS_fp16_activation_checkpointing.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEbb23oGo2TL"
   },
   "source": [
    "### 메모리는 어떤가요?\n",
    "\n",
    "프로파일링은 텐서보드 링크의 `pytorch_profiler`탭에서 사용할 수 있습니다. 활성화 체크포인팅를 사용할 때 `run_fp16_activation_checkpointing_GPU0` 를 확인해 보면 메모리 사용량이 ~3G 피크까지 상당히 감소하는 것을 알 수 있습니다. 이는 일부 활성화가 저장되지 않고 필요할 때 다시 계산되기 때문입니다.\n",
    "그래프를 확대하면 Pytorch CheckpointFunctions를 추적할 수 있습니다.\n",
    "\n",
    "<img src=\"images/profiling_FP16_checkpoiting_memory.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkL6vADto2TL"
   },
   "source": [
    "좋습니다! 다음으로 넘어가기 전에 이전 실행에서 생성된 불필요한 체크포인트를 삭제하여 디스크 공간을 확보해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kIhixUleo2TL"
   },
   "outputs": [],
   "source": [
    "# Clean the checkpoints \n",
    "! rm -rf /dli/megatron/checkpoints/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eB_P8641o2TL"
   },
   "source": [
    "---\n",
    "# 4.3 그래디언트 축적 \n",
    "\n",
    "\n",
    "배치 크기를 늘리는 또 다른 방법은 그래디언트 축적(Gradient Accumulation)을 사용하는 것입니다. 분산 데이터 병렬에서처럼 워커 간에 데이터를 분할하는 대신, 모델의 매개 변수를 업데이트하기 전에 동일한 워커가 여러 배치를 처리하고 그래디언트을 누적합니다.\n",
    "\n",
    "[NVIDIA APEX Library](https://github.com/NVIDIA/apex#quick-start) 는 자동 혼합 정밀도로 그래디언트 축적을 사용할 때 최적화된 구현 방식을 제공합니다. 이 구현 방식은 그래디언트의 불필요한 이중 정밀도 복사본들을 제거하기 위해 먼저 낮은 정밀도로 축적한 후 다시 이중 정밀도로 돌아갑니다. Megatron-LM  라이브러리는 APEX 구현을 사용합니다.  \n",
    "\n",
    "\n",
    "Gradient Accumulation(그래디언트 누적)을 사용하여 Megatron-LM 사전 훈련을 실행하려면 마이크로 배치 크기를 동일하게 유지하면서 글로벌 배치 크기를 늘리기만 하면 됩니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "dRWGbXRPo2TM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /dli/code/pretrain_gpt_2Node4GPU_increase_BS_fp16_activation_checkpointing_gradient_accumulation.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile /dli/code/pretrain_gpt_2Node4GPU_increase_BS_fp16_activation_checkpointing_gradient_accumulation.sh\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=dli_2nodes\n",
    "#SBATCH --nodes=2\n",
    "#SBATCH --ntasks-per-node=1       \n",
    "#SBATCH --cpus-per-task=32 ### Number of threads per task (OMP threads)\n",
    "#SBATCH -o /dli/megatron/logs/%j.out\n",
    "#SBATCH -e /dli/megatron/logs/%j.err\n",
    "\n",
    "set -x -e\n",
    "\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "\n",
    "# Distributed training args\n",
    "NNODES=2\n",
    "GPUS_PER_NODE=2\n",
    "TP_SIZE=1\n",
    "PP_SIZE=1 \n",
    "\n",
    "# SLURM args\n",
    "MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)\n",
    "MASTER_PORT=6000\n",
    "\n",
    "# Distributed training \n",
    "MICRO_BATCH_SIZE=4      \n",
    "GLOBAL_BATCH_SIZE=64    \n",
    "\n",
    "# Model architecture \n",
    "NLAYERS=12\n",
    "NHIDDEN=768\n",
    "NHEADS=32\n",
    "SEQ_LEN=1024\n",
    "VOCAB_SIZE=50257\n",
    "\n",
    "# Data Paths\n",
    "DATA_OUTPUT_PATH=/dli/megatron/checkpoints/test\n",
    "CHECKPOINT_PATH=/dli/megatron/checkpoints\n",
    "TENSORBOARD_PATH=/dli/megatron/tensorboard\n",
    "LOGS_PATH=/dli/megatron/logs\n",
    "VOCAB_FILE=/dli/data/GPT-2_assets/gpt2-vocab.json\n",
    "MERGE_FILE=/dli/data/GPT-2_assets/gpt2-merges.txt\n",
    "DATA_PATH=/dli/data/GPT-2_assets/my-gpt2_text_document\n",
    "\n",
    "NAME=\"log_2Nodes4GPUS_increase_GBS_fp16_activation_checkpointing_gradient_accumulation\"        \n",
    "\n",
    "\n",
    "OPTIMIZER_ARGS=\" \\\n",
    "            --optimizer adam \\\n",
    "            --adam-beta1 0.9 \\\n",
    "            --adam-beta2 0.95 \\\n",
    "            --adam-eps 1e-8 \\\n",
    "            --lr 6e-5 \\\n",
    "            --min-lr 6e-6 \\\n",
    "            --lr-decay-style cosine \\\n",
    "            --lr-decay-iters 800 \\\n",
    "            --lr-warmup-fraction .01 \\\n",
    "            --clip-grad 1.0 \\\n",
    "            --weight-decay 1e-1 \\\n",
    "            --exit-duration-in-mins 1190 \\\n",
    "              \"\n",
    "\n",
    "GPT_ARGS=\" \\\n",
    "            --num-layers $NLAYERS \\\n",
    "            --hidden-size $NHIDDEN \\\n",
    "            --num-attention-heads $NHEADS \\\n",
    "            --seq-length $SEQ_LEN \\\n",
    "            --max-position-embeddings $SEQ_LEN \\\n",
    "            --micro-batch-size $MICRO_BATCH_SIZE \\\n",
    "            --global-batch-size $GLOBAL_BATCH_SIZE \\\n",
    "            --train-iters 100 \\\n",
    "            --vocab-file $VOCAB_FILE \\\n",
    "            --merge-file $MERGE_FILE \\\n",
    "            --init-method-std 0.006 \\\n",
    "            --fp16 \\\n",
    "            --activations-checkpoint-method uniform \\\n",
    "            $OPTIMIZER_ARGS \\\n",
    "            \"\n",
    "\n",
    "OUTPUT_ARGS=\" \\\n",
    "            --log-interval 10 \\\n",
    "            --save-interval 300 \\\n",
    "            --eval-interval 1000 \\\n",
    "            --eval-iters 10 \\\n",
    "            --tensorboard-dir $TENSORBOARD_PATH \\\n",
    "            --tensorboard-queue-size 1 \\\n",
    "            --log-timers-to-tensorboard \\\n",
    "            --log-batch-size-to-tensorboard \\\n",
    "            --log-validation-ppl-to-tensorboard \\\n",
    "            --profile-execution True \\\n",
    "            --profile-name fp16_activation_checkpointing_gradient_accumulation \\\n",
    "            \"\n",
    "\n",
    "export LAUNCHER=\"python -u -m torch.distributed.launch \\\n",
    "             --nproc_per_node $GPUS_PER_NODE \\\n",
    "             --nnodes $NNODES \\\n",
    "             --master_addr $MASTER_ADDR \\\n",
    "             --master_port $MASTER_PORT \\\n",
    "             \"\n",
    "\n",
    "export CMD=\" \\\n",
    "             /dli/megatron/Megatron-LM/pretrain_gpt.py \\\n",
    "             --tensor-model-parallel-size $TP_SIZE \\\n",
    "             --pipeline-model-parallel-size $PP_SIZE \\\n",
    "             $GPT_ARGS \\\n",
    "             $OUTPUT_ARGS \\\n",
    "             --save $CHECKPOINT_PATH \\\n",
    "             --data-path $DATA_PATH \\\n",
    "             --data-impl mmap \\\n",
    "             --split 949,50,1 \\\n",
    "             --distributed-backend nccl \\\n",
    "           \"\n",
    "\n",
    "clear; srun --jobid $SLURM_JOBID bash -c 'NCCL_DEBUG=INFO  $LAUNCHER --node_rank $SLURM_PROCID $CMD' 2>&1 | tee -a $LOGS_PATH/$NAME.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXQmbngFo2TM"
   },
   "source": [
    "이제 이전의 sbatch 스크립트 [pretrain_gpt_2Node4GPU_increase_BS_fp16_activation_checkpointing_gradient_accumulation.sh](/dli/code/pretrain_gpt_2Node4GPU_increase_BS_fp16_activation_checkpointing_gradient_accumulation.sh)를 실행합니다. `squeue` 명령어를 사용하여 SLURM 대기열을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_kYIhaEFo2TM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 15\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "                15  slurmpar dli_2nod    admin  R       0:01      2 slurmnode[1-2]\n"
     ]
    }
   ],
   "source": [
    "# Submit the 2 nodes jobs\n",
    "!sbatch /dli/code/pretrain_gpt_2Node4GPU_increase_BS_fp16_activation_checkpointing_gradient_accumulation.sh\n",
    "\n",
    "# Check the SLURM queue\n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQ00aZJmo2TM"
   },
   "source": [
    "Megatron GPT3 사전 훈련의 성능을 이해하기 위해 생성된 [로그](./megatron/logs/log_2Nodes4GPUS_increase_GBS_fp16_activation_checkpointing_gradient_accumulation.txt) 를 확인하고 강사와 논의해 봅니다.\n",
    "\n",
    "그래디언트 축적을 활성화하거나 비활성화할 때 GPU당 마이크로 배치 수를 비교해 보겠습니다. 비교를 위해서는 그래디언트 누적이 없는 이전 실행 줄과 비교해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gIUMVcoio2TN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without gradient accumulation:\n",
      "setting number of micro-batches to constant 1\n",
      "With 4 gradient accumulation:\n",
      "setting number of micro-batches to constant 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Without gradient accumulation:\")\n",
    "!grep constant /dli/megatron/logs/log_2Nodes4GPUS_increase_GBS_fp16_activation_checkpointing.txt\n",
    "\n",
    "print(\"With 4 gradient accumulation:\")\n",
    "!grep constant /dli/megatron/logs/log_2Nodes4GPUS_increase_GBS_fp16_activation_checkpointing_gradient_accumulation.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "3fO-42uNo2TN"
   },
   "outputs": [],
   "source": [
    "!grep elapsed /dli/megatron/logs/log_2Nodes4GPUS_increase_GBS_fp16_activation_checkpointing_gradient_accumulation.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8D9WFzyno2TN"
   },
   "source": [
    "### 메모리는 어떤가요?\n",
    "\n",
    "프로파일링은 `run_fp16_activation_checkpointing_gradient_accumulation_gpu0` 실행 시 생성된 텐서보드 링크의  `pytorch_profiler` 탭에서 확인 가능합니다.\n",
    "\n",
    "우리는 메모리 추적에서 단계당 4개의 그레디언트 누적 단계들을 볼 수 있습니다. \n",
    "\n",
    "<img src=\"images/profiling_FP16_checkpoiting_gradient_acc_memory.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UxRV8LOo2TN"
   },
   "source": [
    "좋습니다! 다음으로 넘어가기 전에 이전 실행에서 생성된 불필요한 체크포인트를 삭제하여 디스크 공간을 확보해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1CRq81CNo2TN"
   },
   "outputs": [],
   "source": [
    "# Clean the checkpoints \n",
    "! rm -rf /dli/megatron/checkpoints/* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uspE5INvo2TN"
   },
   "source": [
    "---\n",
    "# 4.4 학습 성능\n",
    "\n",
    "합리적인 시간 내에 대규모 신경망을 훈련시키기 위해서는 인프라 확장이 불가피합니다. \n",
    "먼저 트랜스포머 모델의 매개 변수 수를 연산하고 하드웨어 인프라와 실험적으로 관찰된 훈련 처리량에 따라 학습 성능을 추정해 보겠습니다.\n",
    "\n",
    "\n",
    "## 4.4.1 트랜스포머 모델의 매개 변수 수 연산\n",
    "\n",
    "트랜스포머 모델의 파라미터 수는 다음과 같이 계산됩니다:\n",
    "\n",
    "$P = 12 l h^2 (1 + \\frac{13}{12h} + \\frac{V+s}{12lh})$ where:\n",
    "- $l$ = Number of Layers\n",
    "- $h$ = Hidden Size \n",
    "- $V$ = Vocabulary Size \n",
    "- $s$ = Sequence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "q9Ty5Wl7o2TO"
   },
   "outputs": [],
   "source": [
    "# Number of parameters of the Transformers model\n",
    "def calculate_number_parameters(l,h,s,V):\n",
    "    # Compute the number of parameters of the model\n",
    "    P=12*l*h*h *(1+ (13/(12*h)) + ((V+s)/(12*l*h)))\n",
    "    print(\"The number of parameters for the GPT architecture is: {} \\n\".format(int(P)))\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-DSb_y8ko2TO"
   },
   "source": [
    "예를 들어, 40개의 레이어, 6144의 히든 사이즈, 50257의 vocabulary 크기, 1024의 시퀀스 길이를 가진 트랜스포머 모델의 매개 변수 수를 계산해 보겠습니다. 계산에 따르면 이 모델은 약 180억 개의 매개 변수여야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "30OnXwmgo2TO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters for the GPT architecture is: 18437806080 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the model architecture parameters\n",
    "l=40\n",
    "h=6144\n",
    "s=1048\n",
    "V=50257\n",
    "    \n",
    "P=calculate_number_parameters(l,h,s,V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1YNPZflo2TO"
   },
   "source": [
    "## 4.4.2 연습: 모델의 매개 변수 수 연산\n",
    "\n",
    "이전 노트북에서 실험한 모델의 매개 변수 수를 연산합니다.\n",
    "이전 노트북의 Megaton-LM GPT 사전 훈련 스크립트에서 모델 아키텍처 인자들을 살펴보십시오. \n",
    "\n",
    "막히면 [해설서](solutions/ex4.1.2.ipynb)를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "jpc16BJmo2TO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters for the GPT architecture is: 18437806080 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18437806080.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set our model architecture parameters\n",
    "l=40\n",
    "h=6144\n",
    "s=1048\n",
    "V=50257\n",
    "    \n",
    "calculate_number_parameters(l,h,s,V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0C6LXe4po2TO"
   },
   "source": [
    "## 4.4.3 GPU당 이론상 최대 FLOP/초 연산\n",
    "\n",
    "[Scaling Language Model Training to a Trillion Parameters Using Megatron](https://arxiv.org/pdf/2104.04473.pdf) 논문에서 자세히 설명한 바와 같이 모델에서 대부분의 부동소수점 연산은 행렬 곱(GEMMs)에서 수행됩니다. 이러한 GEMMs 연산만 고려할 경우 반복당 FLOP 수는 다음과 같습니다. \n",
    "\n",
    "$F = 96 B s l h^2 (1 + \\frac{s}{6h} + \\frac{V}{16lh})$ where $B$ is the batch size. \n",
    "\n",
    "그리고 반복당 소요 시간`Time_per_iteration_second` 에 대한 추정치가 있는 경우, 초당 및 GPU당 이론 상 최대 FLOP를 계산하고 비교함으로써 GPU 사용량을 추정할 수 있습니다. \n",
    "\n",
    "다음 표는 A100 GPU로 구성된 SuperPOD 클러스터에서 Megatron-LM  라이브러리를 사용하여 사전 훈련을 받은 여러 GPT 모델들의 크기별(1.7B~1조)의 훈련 성능을 보여줍니다.\n",
    "<img src=\"https://github.com/NVIDIA/Megatron-LM/blob/main/images/cases_april2021.png?raw=true\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8jfhBYHao2TP"
   },
   "outputs": [],
   "source": [
    "# Theoretical peak FLOP per second per GPU - with activation checkpointing (2 forwards and 1 backward)\n",
    "def calculate_Theoretical_peak_FLOP_s_GPU(B,s, l,h,number_GPUs,Time_per_iteration_second):\n",
    "    # The number of FLOPs per iteration\n",
    "    F = 96*B*s* l*h*h *(1 + s/ (6*h) + V/(16*l*h))/1e+12\n",
    "    \n",
    "    #Theoretical peak FLOP per second per GPU\n",
    "    PF= (F/Time_per_iteration_second/number_GPUs)\n",
    "    print(\"Theoretical peak FLOP/s/GPU: {}\\n\".format(PF))\n",
    "    \n",
    "    # Percentage of theoretical peak FLOP/s on a A100 FP16 (change according the hardware)\n",
    "    GPU_usage= PF/ 312 *100\n",
    "    print(\"Percentage of theoretical peak FLOP/s: {}%\".format(GPU_usage))\n",
    "    \n",
    "    return PF, GPU_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdC7YJ0Fo2TP"
   },
   "source": [
    "이전 기능에서 이론상 최대 FLOP/s의 백분율은 **FP16/BF16 = 312** 의 **A100** 하드웨어 기능을 기반으로 합니다. 또한 해당 텐서 코어 GPU 성능 사양에 따라 업데이트 될 필요가 있습니다. [Ampere architecture specifications](https://developer.nvidia.com/blog/nvidia-ampere-architecture-in-depth/) 문서에서 더 자세히 알아보세요.\n",
    "\n",
    "\n",
    "\n",
    "글로벌 배치 크기가 512인 16개의 GPU에서 사전 훈련된 이전 18B 매개 변수 모델을 고려하면 반복당 시간이 32.09초입니다. \n",
    "GPU 당 이론상 최대 초당 FLOP와 GPU 활용률을 계산해 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ua7Xk_mJo2TP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical peak FLOP/s/GPU: 157.7296879710454\n",
      "\n",
      "Percentage of theoretical peak FLOP/s: 50.55438717020686%\n"
     ]
    }
   ],
   "source": [
    "global_batch_size=512\n",
    "number_GPUs=16\n",
    "Time_per_iteration_second=32.09\n",
    "\n",
    "# Considering the 18B parameters model\n",
    "l=40\n",
    "h=6144\n",
    "s=1048\n",
    "V=50257\n",
    "    \n",
    "PF,GPU_usage=calculate_Theoretical_peak_FLOP_s_GPU(global_batch_size,s, l,h,number_GPUs,Time_per_iteration_second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JFFyTD1o2TP"
   },
   "source": [
    "## 4.4.4 에폭 당 훈련 시간 (Training  Duration / Epoch) 추정\n",
    "\n",
    "모델, 데이터 세트 및 하드웨어 크기에 따라 에폭 당 훈련 시간을 추정할 수 있습니다. 훈련 시간(초)은 아래의 방정식으로 근사합니다.\n",
    "\n",
    "Training time (sec) $\\approx \\frac{8*T*P}{n * PF}$ where: \n",
    "- $T$ = Number of tokens in the dataset\n",
    "- $P$ = Numbers of parameters \n",
    "- $n$ = Number of GPUs\n",
    "- $PF$ = Achieved teraFLOP/s per GPU\n",
    "\n",
    "자세한 내용은 [[Scaling Language Model Training to a Trillion Parameters Using Megatron](https://arxiv.org/pdf/2104.04473.pdf) 논문에서 확인할 수 있습니다.\n",
    "\n",
    "다음 2개의 셀을 실행하여 $T$=3000억 토큰의 데이터 세트에서 훈련된 18B 매개 변수 모델에 대한 훈련 시간을 추정해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "V4KPCdC-o2TP"
   },
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "# Estimate the training time\n",
    "def estimate_days_needed(T , P , N ,PF):  \n",
    "    compute_sec=8*T*P/(N*PF*10e12)\n",
    "    # Convert compute seconds to days\n",
    "    to_days=round(compute_sec/(3600*24))\n",
    "    print(\"This language model will need {} days per epoch.\".format(colored(str(to_days),'blue', attrs=['bold'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "iDRhNfl4o2TQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This language model will need \u001b[1m\u001b[34m203\u001b[0m days per epoch.\n"
     ]
    }
   ],
   "source": [
    "# Number of tokens in the dataset\n",
    "T=300*10e09\n",
    "\n",
    "estimate_days_needed(T,P,number_GPUs,PF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5inDprNo2TQ"
   },
   "source": [
    "이 결과, 203일이 소요되며, 이는 300B 토큰의 데이터 세트가 있는 16개의 GPU (2개 노드)에서 18B 모델을 훈련하는 데 거의 **7개월**이 소요됩니다! \n",
    "\n",
    "이 경우 적절한 시간 내에 모델을 훈련하기 위해 노드 수를 확장하는 것이 불가피합니다. \n",
    "\n",
    "예를 들어,  $n$=1024 A100 GPU에서 $T$=3000억 개의 토큰 데이터 세트에 대해 훈련된 $P$=1750억 개의 파라미터를 가진 GPT-3 모델을 생각해 보십시오. 1536의 배치 크기를 사용하여 GPU당 $F$=140 teraFLOP/s를 달성합니다. 따라서 이 모델을 훈련하는 데 필요한 시간은 **34일**입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce3C6LIxo2TQ"
   },
   "source": [
    "---\n",
    "<h2 style=\"color:green;\">축하합니다!</h2>\n",
    "\n",
    "다음으로 넘어가기 전에 대기열에서 실행 중이거나 대기 중인 작업이 없는지 확인해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "t3REHN7To2TQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n"
     ]
    }
   ],
   "source": [
    "# Check the SLURM jobs queue \n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_E14PW6o2TQ"
   },
   "source": [
    "아직 실행 중이거나 보류 중인 작업이 있는 경우 다음 셀을 실행하고 `scancel` 명령을 사용하여 모든 어드민 사용자의 작업을 취소합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "QvjIU5Vmo2TQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n"
     ]
    }
   ],
   "source": [
    "# Cancel admin user jobs\n",
    "! scancel -u $USER\n",
    "\n",
    "# Check again the SLURM jobs queue (should be either empty, or the status TS column should be CG)\n",
    "! squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rwpE-9qo2TR"
   },
   "source": [
    "다음 노트북에서는 대규모 신경망을 훈련하는 데 사용되는 다른 기술을 실험하고 컴퓨터 비전을 위한 사용법을 시연할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "04_GPT_LM_pretrainings_optimizations.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
