{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNrb4IzkEKxR"
   },
   "source": [
    "<img src=\"./images/DLI_Header.png\" style=\"width: 400px;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pb3tUP7mEKxa"
   },
   "source": [
    "# 3.0 멀티 노드 분산 학습 전략\n",
    "\n",
    "이번 노트북에서는 멀티 노드에서 [Megatron-LM](https://github.com/NVIDIA/Megatron-LM) GPT 사전 훈련을 실행하는 방법에 대해 알아보겠습니다.\n",
    "\n",
    "\n",
    "## 목표\n",
    "\n",
    "이번 노트북의 목표는 다음과 같습니다:\n",
    "* Megatron-LM 스크립트의 간단한 멀티 노드 학습 실행\n",
    "* 데이터, 텐서 및 파이프라인 병렬 분포를 사용하여 하이브리드 다중 노드 실행\n",
    "\n",
    "\n",
    "**[3.1 Megatron-LM GPT 사전 훈련의 멀티 노드 트레이닝 실행](#1.1-The-hardware-overview)<br>**\n",
    "**[3.2 데이터 병렬화로 멀티-노드 실행](#1.1-The-hardware-overview)<br>**\n",
    "**[3.3 인터/인트라 노드 커뮤니케이션](#1.1-The-hardware-overview)<br>**\n",
    "**[3.4 프로파일링](#1.1-Profiling)<br>**\n",
    "**[3.5 연습: 하이브리드 분산 학습 전략](#1.1-The-hardware-overview)<br>**\n",
    "**[3.6 GPU 별 배치 사이즈 증가하기](#1.1-The-hardware-overview)<br>**\n",
    "\n",
    "### 이전 실행/보류 중인 작업 취소하기\n",
    "\n",
    "다음으로 이동하기 전에 SLURM 대기열에서 아직 실행 중이거나 대기 중인 작업이 없는지 확인하십시오. 다음 셀을 실행하여 SLURM 작업 대기열을 확인합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F7LUO5JFEKxc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n"
     ]
    }
   ],
   "source": [
    "# Check the SLURM jobs queue \n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQMnCLYOEKxf"
   },
   "source": [
    "아직 실행 중이거나 보류 중인 작업이 있는 경우 다음 셀을 실행하여 `scancel`  명령어를 사용하여 모든 사용자의 작업을 취소합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7DICfRdwEKxg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n"
     ]
    }
   ],
   "source": [
    "# Cancel admin user jobs\n",
    "! scancel -u $USER\n",
    "\n",
    "# Check again the SLURM jobs queue (should be either empty, or the status TS column should be CG)\n",
    "! squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tm9L_X-GEKxg"
   },
   "source": [
    "---\n",
    "# 3.1 Megatron-LM GPT 사전 학습의 다중 노드 학습 실행\n",
    "\n",
    "이전 노트북에서는 노드 1개를 할당한 후 대화형 세션에서 작업을 제출했습니다. \n",
    "\n",
    "멀티-노드 작업의 경우 SLURM 스케줄러를 활용해야 합니다. 기본적으로 Megatron-LM을 사용한 멀티 노드 훈련은 [PyTorch distributed launcher](https://pytorch.org/docs/stable/distributed.html)의 [NVIDIA Collective Communications Library - NCCL](https://developer.nvidia.com/nccl) 분산 백엔드를 사용합니다.\n",
    "\n",
    "2-노드 실행의 경우`SBATCH`스크립트를 사용합니다. 파이썬 실행 명령과 해당 인자들는 단일 노드에서 수행된 방법과 유사하지만 리소스 할당을 위해 추가적인`SBATCH`인자가 필요합니다. \n",
    "\n",
    "먼저 데이터 병렬 만을 사용하여 2개 노드에 대해  Megatron-LM GPT 사전 훈련을 실행하는 것으로 시작합니다. 다시 말하면, 모델은 할당된 4개의 GPU에 복사되어 각각 다른 데이터 배치를 처리합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpVv1XYVEKxh"
   },
   "source": [
    "# 3.2 데이터 병렬화를 통한 멀티 노드 실행\n",
    "\n",
    "이전의 2-GPU 데이터 병렬 실행에서, 각 GPU에 의해 처리되는 배치 크기는`--global-batch-size`에서 설정된 글로벌 배치 크기 4에 해당하는 `--micro-batch-size`에서 설정된 2 였습니다. \n",
    "\n",
    "4개의 GPU를 사용할 때 GPU당 마이크로 배치 크기를 2로 유지하고 글로벌 배치 크기를 8로 설정할 수 있습니다(MICRO_BATCH_SIZE $ \\times $ 4).\n",
    "\n",
    "리소스를 할당하고 실행하기 전에 스크립트를 살펴보겠습니다. \n",
    "\n",
    "리소스 할당에 대한 `SBATCH` 인수를 확인하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CgQi4GF2EKxi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=dli_2nodes\n",
      "#SBATCH --nodes=2\n",
      "#SBATCH --ntasks-per-node=1       \n",
      "#SBATCH --cpus-per-task=32 ### Number of threads per task (OMP threads)\n",
      "#SBATCH -o /dli/megatron/logs/%j.out\n",
      "#SBATCH -e /dli/megatron/logs/%j.err\n",
      "\n",
      "set -x -e\n",
      "\n",
      "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
      "\n",
      "# Distributed training args\n",
      "NNODES=2\n",
      "GPUS_PER_NODE=2\n",
      "TP_SIZE=1\n",
      "PP_SIZE=1 \n",
      "\n",
      "# SLURM args\n",
      "MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)\n",
      "MASTER_PORT=6000\n",
      "\n",
      "# Distributed training \n",
      "MICRO_BATCH_SIZE=2\n",
      "GLOBAL_BATCH_SIZE=8    # <--- CHANGED HERE\n",
      "\n",
      "# Model architecture \n",
      "NLAYERS=12\n",
      "NHIDDEN=768\n",
      "NHEADS=32\n",
      "SEQ_LEN=1024\n",
      "VOCAB_SIZE=50257\n",
      "\n",
      "# Data Paths\n",
      "DATA_OUTPUT_PATH=/dli/megatron/checkpoints/test\n",
      "CHECKPOINT_PATH=/dli/megatron/checkpoints\n",
      "TENSORBOARD_PATH=/dli/megatron/tensorboard\n",
      "LOGS_PATH=/dli/megatron/logs\n",
      "VOCAB_FILE=/dli/data/GPT-2_assets/gpt2-vocab.json\n",
      "MERGE_FILE=/dli/data/GPT-2_assets/gpt2-merges.txt\n",
      "DATA_PATH=/dli/data/GPT-2_assets/my-gpt2_text_document\n",
      "\n",
      "NAME=\"log_2Nodes4GPUS\"       # <--- CHANGED HERE \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "OPTIMIZER_ARGS=\" \\\n",
      "            --optimizer adam \\\n",
      "            --adam-beta1 0.9 \\\n",
      "            --adam-beta2 0.95 \\\n",
      "            --adam-eps 1e-8 \\\n",
      "            --lr 6e-5 \\\n",
      "            --min-lr 6e-6 \\\n",
      "            --lr-decay-style cosine \\\n",
      "            --lr-decay-iters 800 \\\n",
      "            --lr-warmup-fraction .01 \\\n",
      "            --clip-grad 1.0 \\\n",
      "            --weight-decay 1e-1 \\\n",
      "            --exit-duration-in-mins 1190 \\\n",
      "              \"\n",
      "\n",
      "GPT_ARGS=\" \\\n",
      "            --num-layers $NLAYERS \\\n",
      "            --hidden-size $NHIDDEN \\\n",
      "            --num-attention-heads $NHEADS \\\n",
      "            --seq-length $SEQ_LEN \\\n",
      "            --max-position-embeddings $SEQ_LEN \\\n",
      "            --micro-batch-size $MICRO_BATCH_SIZE \\\n",
      "            --global-batch-size $GLOBAL_BATCH_SIZE \\\n",
      "            --train-iters 100 \\\n",
      "            --vocab-file $VOCAB_FILE \\\n",
      "            --merge-file $MERGE_FILE \\\n",
      "            --init-method-std 0.006 \\\n",
      "            $OPTIMIZER_ARGS \\\n",
      "        \"\n",
      "\n",
      "OUTPUT_ARGS=\" \\\n",
      "            --log-interval 10 \\\n",
      "            --save-interval 300 \\\n",
      "            --eval-interval 1000 \\\n",
      "            --eval-iters 10 \\\n",
      "            --tensorboard-dir $TENSORBOARD_PATH \\\n",
      "            --tensorboard-queue-size 1 \\\n",
      "            --log-timers-to-tensorboard \\\n",
      "            --log-batch-size-to-tensorboard \\\n",
      "            --log-validation-ppl-to-tensorboard \\\n",
      "            --profile-execution True \\\n",
      "            --profile-name baseline \\\n",
      "            \"\n",
      "\n",
      "export LAUNCHER=\"python -u -m torch.distributed.launch \\\n",
      "             --nproc_per_node $GPUS_PER_NODE \\\n",
      "             --nnodes $NNODES \\\n",
      "             --master_addr $MASTER_ADDR \\\n",
      "             --master_port $MASTER_PORT \\\n",
      "             \"\n",
      "\n",
      "export CMD=\" \\\n",
      "             /dli/megatron/Megatron-LM/pretrain_gpt.py \\\n",
      "             --tensor-model-parallel-size $TP_SIZE \\\n",
      "             --pipeline-model-parallel-size $PP_SIZE \\\n",
      "             $GPT_ARGS \\\n",
      "             $OUTPUT_ARGS \\\n",
      "             --save $CHECKPOINT_PATH \\\n",
      "             --data-path $DATA_PATH \\\n",
      "             --data-impl mmap \\\n",
      "             --split 949,50,1 \\\n",
      "             --distributed-backend nccl \\\n",
      "           \"\n",
      "\n",
      "clear; srun --jobid $SLURM_JOBID bash -c 'NCCL_DEBUG=INFO  $LAUNCHER --node_rank $SLURM_PROCID $CMD' 2>&1 | tee -a $LOGS_PATH/$NAME.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# have a look at Megaton-LM GPT pretraining execution on 2 nodes\n",
    "! cat /dli/code/pretrain_gpt_2Node4GPU.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwudshezEKxj"
   },
   "source": [
    "이제 sbatch [script pretrain_gpt_2Node4GPU.sh](./code/pretrain_gpt_2Node4GPU.sh)를 실행합니다.  `squeue` 명령어를 사용하여 SLURM 대기열을 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hnepg3AoEKxk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 9\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "                 9  slurmpar dli_2nod    admin PD       0:00      2 (None)\n"
     ]
    }
   ],
   "source": [
    "# submit the 2 nodes jobs\n",
    "! sbatch /dli/code/pretrain_gpt_2Node4GPU.sh\n",
    "\n",
    "# Check the SLURM queue\n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TF8e3UvwEKxl"
   },
   "source": [
    "마스터 랩 노드에서`nvidia-smi` 명령어를 실행하여 GPU 활용량을 확인할 수 있습니다. 몇 초 후 노드가 할당되고 스크립트가 실행을 시작할 때 아래와 같이 GPU 0,1,2,3이 사용되는 것을 볼 수 있습니다. 수업에서 처음으로 Megatron-LM을 실행하는 경우 코드를 컴파일하는 데 약 6분이 소요됩니다. 그 전까지는 GPU 활동을 볼 수 없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7n8B3QrEKxl"
   },
   "source": [
    "\n",
    "<img src=\"images/2N_4gpus_utilization.png\" width=\"650\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "w8NJGxJ7EKxm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 28 02:19:50 2025       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1B.0 Off |                    0 |\n",
      "| N/A   34C    P0    60W / 300W |   2154MiB / 16160MiB |      3%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   35C    P0    64W / 300W |   2160MiB / 16160MiB |      4%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:00:1D.0 Off |                    0 |\n",
      "| N/A   35C    P0    65W / 300W |   2162MiB / 16160MiB |      3%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   35C    P0    54W / 300W |   2164MiB / 16160MiB |      3%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check GPU utilization on the master node\n",
    "! sleep 10\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ii-PPa3TEKxm"
   },
   "source": [
    "Megatron GPT-3 사전 훈련의 성능을 이해하기 위해 실행 중에 생성된 [로그](./megatron/logs/log_2Nodes4GPUS.txt)를 확인해 봅니다.\n",
    "\n",
    "먼저 실행 내역의 전역 크기를 확인해 보겠습니다. 아래 부분을 확인해 보세요:\n",
    "```\n",
    "using world size: 4, data-parallel-size: 4, tensor-model-parallel size: 1, pipeline-model-parallel size: 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Rq12Qy0bEKxn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using world size: 4, data-parallel-size: 4, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 \n"
     ]
    }
   ],
   "source": [
    "! grep \"using world size:\" /dli/megatron/logs/log_2Nodes4GPUS.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iun2pQMtEKxn"
   },
   "source": [
    "이제 4개의 GPU에 대한 GPT 사전 훈련의 성능을 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xLpruFFYEKxn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 0] (after 10 iterations) memory (MB) | allocated: 1907.2294921875 | max allocated: 10582.0205078125 | reserved: 10922.0 | max reserved: 10922.0\n",
      " iteration       10/     100 | consumed samples:           80 | elapsed time per iteration (ms): 808.1 | learning rate: 6.000E-05 | global batch size:     8 | lm loss: 1.048027E+01 | loss scale: 1.0 | grad norm: 4.595 | number of skipped iterations:   0 | number of nan iterations:   0 |\n"
     ]
    }
   ],
   "source": [
    "! grep iteration /dli/megatron/logs/log_2Nodes4GPUS.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0sSvXPOEKxo"
   },
   "source": [
    "추출 로그에서 4개의 GPU (노드당 2개의 GPU)를 사용하는 동안 훈련 성능을 확인할 수 있습니다. \n",
    "\n",
    "```\n",
    "iteration      100/     100 | consumed samples:          800 | elapsed time per iteration (ms): 537.3 | learning rate: 5.822E-05 | global batch size:     8 | lm loss: 7.448950E+00 | loss scale: 1.0 | grad norm: 1.303 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
    "```\n",
    "\n",
    "이 결과를 1개 노드 실행 결과와 비교해보고 강사와 함께 논의해 봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NT4RO5mHEKxo"
   },
   "source": [
    "---\n",
    "# 3.3 노드 내/노드 간 통신\n",
    "\n",
    "이전 실행에서 아래와 같이 훈련 중에 NCCL 디버그 로그 트레이스를 출력하기 위해 NCCL 변수 `NCCL_DEBUG=INFO`를 추가한 것을 알 수 있습니다. \n",
    "\n",
    "![title](images/nodes_communication.png)\n",
    "\n",
    "\n",
    "이를 통해 훈련 중에 GPU와 노드 간에 사용되는 네트워킹 유형을 확인할 수 있습니다. \n",
    "\n",
    "GPU-GPU 간 직접 통신은 `P2P/IPC` 로 다시 게시되는 반면 노드 내 통신은 `NET/Socket/0`을 통한 것으로 보고됩니다.\n",
    "구성 환경에서 GPU 간 직접 통신은 GPU0<->GPU1 and GPU2<->GPU3 처럼 노드들 간에 사용되어야 합니다. \n",
    "\n",
    "이전 실행에서 NCCL이 기록한 [로그](./megatron/logs/log_2Nodes4GPUS.txt) 를 확인해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xmsVU_yqEKxo",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slurmnode1:1519:1686 [0] NCCL INFO Channel 00/02 :    0   1   2   3\n",
      "slurmnode1:1519:1686 [0] NCCL INFO Channel 01/02 :    0   1   2   3\n",
      "slurmnode1:1519:1686 [0] NCCL INFO Channel 00 : 3[1e0] -> 0[1b0] [receive] via NET/Socket/0\n",
      "slurmnode1:1519:1686 [0] NCCL INFO Channel 01 : 3[1e0] -> 0[1b0] [receive] via NET/Socket/0\n",
      "slurmnode1:1519:1686 [0] NCCL INFO Channel 00 : 0[1b0] -> 1[1c0] via direct shared memory\n",
      "slurmnode1:1519:1686 [0] NCCL INFO Channel 01 : 0[1b0] -> 1[1c0] via direct shared memory\n",
      "slurmnode1:1520:1687 [1] NCCL INFO Channel 00 : 1[1c0] -> 2[1d0] [send] via NET/Socket/0\n",
      "slurmnode1:1520:1687 [1] NCCL INFO Channel 01 : 1[1c0] -> 2[1d0] [send] via NET/Socket/0\n",
      "slurmnode1:1520:1687 [1] NCCL INFO Channel 00 : 1[1c0] -> 0[1b0] via direct shared memory\n",
      "slurmnode1:1520:1687 [1] NCCL INFO Channel 01 : 1[1c0] -> 0[1b0] via direct shared memory\n",
      "slurmnode1:1519:1686 [0] NCCL INFO Channel 00 : 2[1d0] -> 0[1b0] [receive] via NET/Socket/0\n",
      "slurmnode1:1519:1686 [0] NCCL INFO Channel 01 : 2[1d0] -> 0[1b0] [receive] via NET/Socket/0\n",
      "slurmnode1:1519:1686 [0] NCCL INFO Channel 00 : 0[1b0] -> 2[1d0] [send] via NET/Socket/0\n",
      "slurmnode1:1519:1686 [0] NCCL INFO Channel 01 : 0[1b0] -> 2[1d0] [send] via NET/Socket/0\n",
      "slurmnode1:1519:1710 [0] NCCL INFO Channel 00/02 :    0   1   2   3\n",
      "slurmnode1:1519:1710 [0] NCCL INFO Channel 01/02 :    0   1   2   3\n",
      "slurmnode1:1519:1710 [0] NCCL INFO Channel 00 : 3[1e0] -> 0[1b0] [receive] via NET/Socket/0\n",
      "slurmnode1:1519:1710 [0] NCCL INFO Channel 01 : 3[1e0] -> 0[1b0] [receive] via NET/Socket/0\n",
      "slurmnode1:1519:1710 [0] NCCL INFO Channel 00 : 0[1b0] -> 1[1c0] via direct shared memory\n",
      "slurmnode1:1519:1710 [0] NCCL INFO Channel 01 : 0[1b0] -> 1[1c0] via direct shared memory\n",
      "slurmnode1:1520:1711 [1] NCCL INFO Channel 00 : 1[1c0] -> 2[1d0] [send] via NET/Socket/0\n",
      "slurmnode1:1520:1711 [1] NCCL INFO Channel 01 : 1[1c0] -> 2[1d0] [send] via NET/Socket/0\n",
      "slurmnode1:1520:1711 [1] NCCL INFO Channel 00 : 1[1c0] -> 0[1b0] via direct shared memory\n",
      "slurmnode1:1520:1711 [1] NCCL INFO Channel 01 : 1[1c0] -> 0[1b0] via direct shared memory\n",
      "slurmnode1:1519:1710 [0] NCCL INFO Channel 00 : 2[1d0] -> 0[1b0] [receive] via NET/Socket/0\n",
      "slurmnode1:1519:1710 [0] NCCL INFO Channel 01 : 2[1d0] -> 0[1b0] [receive] via NET/Socket/0\n",
      "slurmnode1:1519:1710 [0] NCCL INFO Channel 00 : 0[1b0] -> 2[1d0] [send] via NET/Socket/0\n",
      "slurmnode1:1519:1710 [0] NCCL INFO Channel 01 : 0[1b0] -> 2[1d0] [send] via NET/Socket/0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 00/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 01/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 02/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 03/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 04/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 05/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 06/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 07/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 08/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 09/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 10/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 11/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 12/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 13/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 14/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 15/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 16/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 17/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 18/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 19/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 20/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 21/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 22/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 23/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 24/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 25/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 26/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 27/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 28/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 29/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 30/32 :    0\n",
      "slurmnode1:1520:1719 [1] NCCL INFO Channel 31/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 00/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 01/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 02/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 03/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 04/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 05/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 06/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 07/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 08/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 09/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 10/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 11/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 12/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 13/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 14/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 15/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 16/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 17/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 18/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 19/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 20/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 21/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 22/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 23/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 24/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 25/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 26/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 27/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 28/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 29/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 30/32 :    0\n",
      "slurmnode1:1519:1718 [0] NCCL INFO Channel 31/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 00/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 01/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 02/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 03/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 04/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 05/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 06/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 07/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 08/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 09/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 10/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 11/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 12/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 13/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 14/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 15/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 16/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 17/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 18/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 19/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 20/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 21/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 22/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 23/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 24/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 25/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 26/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 27/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 28/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 29/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 30/32 :    0\n",
      "slurmnode1:1520:1725 [1] NCCL INFO Channel 31/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 00/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 01/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 02/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 03/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 04/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 05/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 06/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 07/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 08/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 09/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 10/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 11/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 12/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 13/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 14/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 15/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 16/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 17/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 18/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 19/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 20/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 21/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 22/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 23/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 24/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 25/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 26/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 27/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 28/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 29/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 30/32 :    0\n",
      "slurmnode1:1519:1727 [0] NCCL INFO Channel 31/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 00/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 00/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 01/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 01/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 02/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 02/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 03/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 03/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 04/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 04/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 05/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 05/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 06/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 06/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 07/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 07/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 08/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 08/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 09/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 09/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 10/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 10/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 11/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 11/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 12/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 12/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 13/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 13/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 14/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 14/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 15/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 15/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 16/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 16/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 17/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 17/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 18/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 18/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 19/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 19/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 20/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 20/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 21/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 21/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 22/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 22/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 23/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 23/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 24/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 24/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 25/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 25/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 26/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 26/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 27/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 27/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 28/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 28/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 29/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 29/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 30/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 30/32 :    0\n",
      "slurmnode1:1520:1979 [1] NCCL INFO Channel 31/32 :    0\n",
      "slurmnode1:1519:1978 [0] NCCL INFO Channel 31/32 :    0\n"
     ]
    }
   ],
   "source": [
    "! grep Channel /dli/megatron/logs/log_2Nodes4GPUS.txt | grep slurmnode1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfPUn5zZEKxp"
   },
   "source": [
    "---\n",
    "# 3.4 학습 모니터링 및 프로파일링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-feBgASEKxp"
   },
   "source": [
    "지금까지 Megatron-LM으로 학습 실행을 모니터링하는 작업은 텍스트 로그 파일을 통해 수행되었습니다. 그러나 하이퍼파라미터와 훈련/평가 지표의 Tensorboard 시각화를 통해 훈련 모니터링도 가능합니다. 또한 시각화는 훈련 중에 모델을 디버깅하고 최적화하는 데 도움이 될 수 있습니다.\n",
    "\n",
    "## 3.4.1 Tensorboard에서 학습 메트릭 시각화\n",
    "\n",
    "<img src=\"images/tensorboard1.png\" width=\"950\"/>\n",
    "\n",
    "이전  Megatron-LM 실행에서 텐서보드 이벤트를 기록하기 위한 인수를 설정했습니다. 이전의 모든 실험의 그래프는 `megatron/tensorboard/` 폴더에서 확인할 수 있습니다.\n",
    "\n",
    "다음 셀을 실행하여 브라우저 용 텐서보드 링크를 만듭니다. 그런 다음 링크를 클릭하면 지정된`Tensorboard` 디렉토리에 저장된 실험 메트릭 그래프를 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "OahvehseEKxp"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "const href = window.location.hostname +'/tensorboard/';\n",
       "let a = document.createElement('a');\n",
       "let link = document.createTextNode('Open Tensorboard!');\n",
       "a.appendChild(link);\n",
       "a.href = \"http://\" + href;\n",
       "a.style.color = \"navy\"\n",
       "a.target = \"_blank\"\n",
       "element.append(a);\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%js\n",
    "const href = window.location.hostname +'/tensorboard/';\n",
    "let a = document.createElement('a');\n",
    "let link = document.createTextNode('Open Tensorboard!');\n",
    "a.appendChild(link);\n",
    "a.href = \"http://\" + href;\n",
    "a.style.color = \"navy\"\n",
    "a.target = \"_blank\"\n",
    "element.append(a);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KdsgwBlEKxq"
   },
   "source": [
    "## 3.4.2 Tensorboard Pytorch 프로파일러\n",
    "\n",
    "훈련 및 추론 프로세스 동안 병목 현상을 조사하는 데 몇 가지 기존 프로파일링 도구를 사용할 수 있습니다. 이를 통해 가장 비용이 많이 드는 연산, GPU 부족 또는 불필요한 연산과 같은 이슈 사항들을 식별할 수 있습니다. \n",
    "\n",
    "이번 과정에서는 Pytorch 실행 중 성능 메트릭을 수집하는 도구인 [Pytorch Profiler](https://pytorch.org/docs/stable/profiler.html) 를 사용합니다.  [Tensorboard-plugin](https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html) 과 PyTorch Profiler를 함께 사용하면 하드웨어 가속기(TensorCore)를 사용하는지 여부에 관계없이 각 GPU에서 실행되는 몇 가지 연산 척도로 각 GPU 프로세스를 시각화할 수 있습니다. 또한 프로세스를 개선하기 위한 권장 사항도 제공합니다.\n",
    "\n",
    "우리는 GPU_0의 실행만 추적하고, 2개의 훈련 단계 동안 연산을 모니터링하겠습니다. 우리는 `profile-execution`을 *True*로 설정하고`profile-name` 을 *baseline*로 설정하여 프로파일링을 명시했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28hPYPvdEKxq"
   },
   "source": [
    "이전 실행의 경우 프로파일링은 텐서보드 링크의  `pytorch_profiler`탭 에서 사용할 수 있습니다.\n",
    "\n",
    "<img src=\"images/profiling1.png\" width=\"900\"/>\n",
    "\n",
    "텐서보드 페이지를 이미 닫은 경우 다음 셀을 실행하여 링크를 다시 생성할 수 있습니다. 링크를 클릭하여 텐서보드를 연 다음  `PYTORCH_PROFILER` 탭으로 이동합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JpSH9FfOEKxq"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "const href = window.location.hostname +'/tensorboard/';\n",
       "let a = document.createElement('a');\n",
       "let link = document.createTextNode('Open Tensorboard!');\n",
       "a.appendChild(link);\n",
       "a.href = \"http://\" + href;\n",
       "a.style.color = \"navy\"\n",
       "a.target = \"_blank\"\n",
       "element.append(a);\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%js\n",
    "const href = window.location.hostname +'/tensorboard/';\n",
    "let a = document.createElement('a');\n",
    "let link = document.createTextNode('Open Tensorboard!');\n",
    "a.appendChild(link);\n",
    "a.href = \"http://\" + href;\n",
    "a.style.color = \"navy\"\n",
    "a.target = \"_blank\"\n",
    "element.append(a);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4GhXWBdEKxq"
   },
   "source": [
    "프로파일러 페이지는 추적의 오버뷰를 전체적으로 보여줍니다. \n",
    "\n",
    "\n",
    "### 프로파일링 개요\n",
    "홈페이지에는 여러 패널이 표시됩니다:\n",
    "- GPU Summary: GPU 구성 및 활용도를 보여줍니다. 이전 실행에서는 혼합 정밀도 학습을 활성화하지 않았기 때문에 TensorCore가 사용되지 않습니다 (다음 노트북 참고). \n",
    "\n",
    "- Step Time Breakdown: 각 작업에 소요된 실행 시간을 보여줍니다. 이전 실행에서 스텝 시간의 48.5%는 통신에, 41.7%는 GPU의 커널 실행 시간에 활용되었습니다. \n",
    "\n",
    "- Performance Recommendation: 프로세스 개선 방법에 대한 권장 사항을 제공합니다. Gradient Accumulation (그래디언트 축적) 또는 배치 크기를 늘리는 등 이전 실행에 대한 몇 가지 권장 사항을 제공합니다. 또한 프로파일러는 커널 속도를 높이기 위해 자동 혼합 정밀도를 사용하도록 설정할 것을 제안합니다. 다음 섹션에서는 먼저 배치 크기를 늘리는 것으로 시작하여 프로세스에서의 영향(속도 향상 및 메모리 소비 측면)을 살펴보겠습니다.\n",
    "\n",
    "### The Memory View\n",
    "이제 실행 시 메모리 할당 및 할당 해제를 보여 주는 Memory View를 살펴보겠습니다. 메모리 곡선을 확대하면 관련 메모리 이벤트를 볼 수 있습니다.\n",
    "\n",
    "<img src=\"images/profiling4.png\" width=\"750\"/>\n",
    "\n",
    "메모리 할당과 할당 해제는 각각 순방향 및 역방향 패스에 해당합니다. 이 프로세스는 2개의 훈련 단계를 추적하면서 두 번 추적됩니다. 또한 훈련 단계에서 최대 10GB까지 GPU 장치 메모리가 사용됨을 알 수 있습니다. 모델이나 배치 크기를 늘려서 메모리 사용량을 늘릴 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dewYlJPEKxr"
   },
   "source": [
    "좋습니다!\n",
    "다음으로 넘어가기 전에 이전 실행에서 생성된 불필요한 체크포인트를 삭제하여 디스크 공간을 확보해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yYTHvdg9EKxr"
   },
   "outputs": [],
   "source": [
    "# Clean the checkpoints\n",
    "! rm /dli/megatron/checkpoints/* -r "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gv1R_rLoEKxs"
   },
   "source": [
    "---\n",
    "# 3.5 GPU당 배치 크기 증가하기\n",
    "\n",
    "**특별 경고:** 이번 섹션에서는 OOM(Out Of Memory) 문제가 예상됩니다! 걱정 안하셔도 됩니다. 다음 노트북에서 이 문제를 해결하는 몇 가지 방법을 살펴보겠습니다.\n",
    "\n",
    "\n",
    "현재 GPT 모델의 크기는 GPU 메모리에 적합하므로 모델 분산 (텐서 또는 파이프라인 병렬화)가 필요하지 않습니다. \\\n",
    "데이터 병렬화만 사용하면 GPU 메모리에 맞는 최대 배치 크기에 도달할 때까지 GPU당 처리되는 배치 크기를 늘림으로써 훈련 처리량 (초당 처리되는 시퀀스 수)을 향상시킬 수 있습니다.\\\n",
    "각 GPU에서 처리되는 데이터를 두 배로 늘려 확인해 봅시다. 데이터 병렬화만 있는 4개의 GPU (DP_SIZE $= 4$) 를 사용할 경우 GPU 당 마이크로 배치 크기를 2에서 4로 늘림으로써 글로벌 배치 크기는 MICRO_BATCH_SIZE $\\times$ TP_SIZE $= 16$ 이어야 합니다.\n",
    "\n",
    "다음 셀을 실행하여 이번 시나리오에 대한 훈련 스크립트를 준비해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VAFPO79VEKxs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /dli/code/pretrain_gpt_2Node4GPU_DP_4_MBS_4.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile /dli/code/pretrain_gpt_2Node4GPU_DP_4_MBS_4.sh\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=dli_2nodes\n",
    "#SBATCH --nodes=2\n",
    "#SBATCH --ntasks-per-node=1       \n",
    "#SBATCH --cpus-per-task=32 ### Number of threads per task (OMP threads)\n",
    "#SBATCH -o /dli/megatron/logs/%j.out\n",
    "#SBATCH -e /dli/megatron/logs/%j.err\n",
    "\n",
    "set -x -e\n",
    "\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "\n",
    "# Distributed training args\n",
    "NNODES=2\n",
    "GPUS_PER_NODE=2\n",
    "TP_SIZE=1\n",
    "PP_SIZE=1 \n",
    "\n",
    "# SLURM args\n",
    "MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)\n",
    "MASTER_PORT=6000\n",
    "\n",
    "# Distributed training \n",
    "MICRO_BATCH_SIZE=4      # <--- CHANGED HERE\n",
    "GLOBAL_BATCH_SIZE=16    # <--- CHANGED HERE\n",
    "\n",
    "# Model architecture \n",
    "NLAYERS=12\n",
    "NHIDDEN=768\n",
    "NHEADS=32\n",
    "SEQ_LEN=1024\n",
    "VOCAB_SIZE=50257\n",
    "\n",
    "# Data Paths\n",
    "DATA_OUTPUT_PATH=/dli/megatron/checkpoints/test\n",
    "CHECKPOINT_PATH=/dli/megatron/checkpoints\n",
    "TENSORBOARD_PATH=/dli/megatron/tensorboard\n",
    "LOGS_PATH=/dli/megatron/logs\n",
    "VOCAB_FILE=/dli/data/GPT-2_assets/gpt2-vocab.json\n",
    "MERGE_FILE=/dli/data/GPT-2_assets/gpt2-merges.txt\n",
    "DATA_PATH=/dli/data/GPT-2_assets/my-gpt2_text_document\n",
    "\n",
    "NAME=\"log_2Nodes4GPUS_DP_4_MBS_4\"\n",
    "\n",
    "\n",
    "OPTIMIZER_ARGS=\" \\\n",
    "            --optimizer adam \\\n",
    "            --adam-beta1 0.9 \\\n",
    "            --adam-beta2 0.95 \\\n",
    "            --adam-eps 1e-8 \\\n",
    "            --lr 6e-5 \\\n",
    "            --min-lr 6e-6 \\\n",
    "            --lr-decay-style cosine \\\n",
    "            --lr-decay-iters 800 \\\n",
    "            --lr-warmup-fraction .01 \\\n",
    "            --clip-grad 1.0 \\\n",
    "            --weight-decay 1e-1 \\\n",
    "            --exit-duration-in-mins 1190 \\\n",
    "              \"\n",
    "\n",
    "GPT_ARGS=\" \\\n",
    "            --num-layers $NLAYERS \\\n",
    "            --hidden-size $NHIDDEN \\\n",
    "            --num-attention-heads $NHEADS \\\n",
    "            --seq-length $SEQ_LEN \\\n",
    "            --max-position-embeddings $SEQ_LEN \\\n",
    "            --micro-batch-size $MICRO_BATCH_SIZE \\\n",
    "            --global-batch-size $GLOBAL_BATCH_SIZE \\\n",
    "            --train-iters 100 \\\n",
    "            --vocab-file $VOCAB_FILE \\\n",
    "            --merge-file $MERGE_FILE \\\n",
    "            --init-method-std 0.006 \\\n",
    "            $OPTIMIZER_ARGS \\\n",
    "        \"\n",
    "\n",
    "OUTPUT_ARGS=\" \\\n",
    "            --log-interval 10 \\\n",
    "            --save-interval 300 \\\n",
    "            --eval-interval 1000 \\\n",
    "            --eval-iters 10 \\\n",
    "            --tensorboard-dir $TENSORBOARD_PATH \\\n",
    "            --tensorboard-queue-size 1 \\\n",
    "            --log-timers-to-tensorboard \\\n",
    "            --log-batch-size-to-tensorboard \\\n",
    "            --log-validation-ppl-to-tensorboard \\\n",
    "            --profile-execution True \\\n",
    "            --profile-name DP_4_MBS_4 \\\n",
    "            \"\n",
    "\n",
    "export LAUNCHER=\"python -u -m torch.distributed.launch \\\n",
    "             --nproc_per_node $GPUS_PER_NODE \\\n",
    "             --nnodes $NNODES \\\n",
    "             --master_addr $MASTER_ADDR \\\n",
    "             --master_port $MASTER_PORT \\\n",
    "             \"\n",
    "\n",
    "export CMD=\" \\\n",
    "             /dli/megatron/Megatron-LM/pretrain_gpt.py \\\n",
    "             --tensor-model-parallel-size $TP_SIZE \\\n",
    "             --pipeline-model-parallel-size $PP_SIZE \\\n",
    "             $GPT_ARGS \\\n",
    "             $OUTPUT_ARGS \\\n",
    "             --save $CHECKPOINT_PATH \\\n",
    "             --data-path $DATA_PATH \\\n",
    "             --data-impl mmap \\\n",
    "             --split 949,50,1 \\\n",
    "             --distributed-backend nccl \\\n",
    "           \"\n",
    "\n",
    "clear; srun --jobid $SLURM_JOBID bash -c 'NCCL_DEBUG=INFO  $LAUNCHER --node_rank $SLURM_PROCID $CMD' 2>&1 | tee -a $LOGS_PATH/$NAME.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATlmr9pCEKxt"
   },
   "source": [
    "이제 이전 sbatch 스크립트 [pretrain_gpt_2Node4GPU_DP_4_MBS_4.sh](./code/pretrain_gpt_2Node4GPU_DP_4_MBS_4.sh) 를 제출합니다. \n",
    " squeue 명령어을 사용하여 SLURM 대기열을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Sb0tM9MnEKxu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 10\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "                10  slurmpar dli_2nod    admin  R       0:01      2 slurmnode[1-2]\n"
     ]
    }
   ],
   "source": [
    "# submit the 2 nodes jobs\n",
    "! sbatch /dli/code/pretrain_gpt_2Node4GPU_DP_4_MBS_4.sh\n",
    "\n",
    "# Check the SLURM queue\n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTx_N626EKxu"
   },
   "source": [
    "이제 생성된 Megatron GPT-3 사전 훈련 성능을 확인하기 위해 실행 중에 생성된 [로그](./megatron/logs/log_2Nodes4GPUS_hybrid_solution.txt) 파일을 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "pHv7_fFOEKxu"
   },
   "outputs": [],
   "source": [
    "! grep iteration /dli/megatron/logs/log_2Nodes4GPUS_DP_4_MBS_4.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c44CWdEoEKxv"
   },
   "source": [
    "반복당 경과 시간이 표시되지 않습니다. **방금 무슨 일이 일어났을까요??!** \n",
    "\n",
    "\n",
    "우리는 GPU 메모리를 포화시키고 있습니까? 아래 셀을 실행하여 로그에서 RuntimeError 를 검색해 봅니다. 다음 메시지를 주목합니다.\n",
    "```\n",
    "RuntimeError: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 15.78 GiB total capacity; 13.90 GiB already allocated; 302.00 MiB free; 14.43 GiB reserved in total by PyTorch)\n",
    "RuntimeError: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 1; 15.78 GiB total capacity; 13.90 GiB already allocated; 302.00 MiB free; 14.43 GiB reserved in total by PyTorch)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "OCBPlscuEKxv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 15.78 GiB total capacity; 13.87 GiB already allocated; 398.00 MiB free; 14.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "RuntimeErrorRuntimeError: : CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 15.78 GiB total capacity; 13.87 GiB already allocated; 398.00 MiB free; 14.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONFCUDA out of memory. Tried to allocate 512.00 MiB (GPU 1; 15.78 GiB total capacity; 13.87 GiB already allocated; 398.00 MiB free; 14.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 1; 15.78 GiB total capacity; 13.87 GiB already allocated; 398.00 MiB free; 14.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "! grep \"RuntimeError\" /dli/megatron/logs/log_2Nodes4GPUS_DP_4_MBS_4.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_kYYav6EKxv"
   },
   "source": [
    "실제로 GPU 메모리가 지정된 인수를 사용하여 이 트랜스포머 모델 크기를 훈련할 수 없다는 것을 의미하는 `CUDA out of memory` 오류를 보게 되었습니다.\n",
    "\n",
    "GPU당 처리되는 데이터의 양을 두 배로 늘리는 것은 16G 메모리에게는 소화하기 어렵습니다.  \n",
    "\n",
    "다음 실습에서는 모델의 메모리 공간을 줄임으로써 이 문제를 해결하는 방법에 초점을 맞출 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmBvcqXuEKxv"
   },
   "source": [
    "좋습니다. 다음으로 넘어가기 전에 이전 실행에서 생성된 불필요한 체크포인트를 삭제하여 디스크 공간을 확보해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "mMUK5N8YEKxv"
   },
   "outputs": [],
   "source": [
    "# Clean the checkpoints and logs directory\n",
    "! rm -rf /dli/megatron/checkpoints/* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5X_43yh1EKxw"
   },
   "source": [
    "---\n",
    "# 3.6 연습 : 하이브리드 분산 훈련 전략\n",
    "\n",
    "\n",
    "다음 셀에서 \"FIXME\"를 수정하여 텐서 및 파이프라인 병렬로 2개의 노드(4개의 GPU)에서 새로운 Megatron-LM GPT 사전 훈련 실행을 구성해 보겠습니다. \n",
    "\n",
    "텐서와 파이프라인 병렬을 사용하기 위해, 텐서 병렬화를 위한 2개의 GPU와 파이프라인 병렬화를 위한 2개의 GPU를 사용하여 2차원으로 분산 모델을 유지할 수 있습니다. 따라서 리소스는 더 이상 데이터 병렬로 남아 있지 않습니다. 이 경우 `GLOBAL_BATCH_SIZE`는 `MICRO_BATCH_SIZE`와 동일한 크기로 다운그레이드해야 합니다.\n",
    "\n",
    "막히면 [솔루션](solutions/ex3.4.ipynb)에서 힌트를 확인하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "KFpfvZpTEKxw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /dli/code/pretrain_gpt_2Node4GPU_hybrid.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile /dli/code/pretrain_gpt_2Node4GPU_hybrid.sh\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=dli_2nodes\n",
    "#SBATCH --nodes=2\n",
    "#SBATCH --ntasks-per-node=1       \n",
    "#SBATCH --cpus-per-task=32 ### Number of threads per task (OMP threads)\n",
    "#SBATCH -o /dli/megatron/logs/%j.out\n",
    "#SBATCH -e /dli/megatron/logs/%j.err\n",
    "\n",
    "set -x -e\n",
    "\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "\n",
    "# Distributed training args\n",
    "NNODES=2\n",
    "GPUS_PER_NODE=2\n",
    "TP_SIZE=2\n",
    "PP_SIZE=2\n",
    "\n",
    "# SLURM args\n",
    "MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)\n",
    "MASTER_PORT=6000\n",
    "\n",
    "# Distributed training \n",
    "MICRO_BATCH_SIZE=4\n",
    "GLOBAL_BATCH_SIZE=4\n",
    "\n",
    "# Model architecture \n",
    "NLAYERS=12\n",
    "NHIDDEN=768\n",
    "NHEADS=32\n",
    "SEQ_LEN=1024\n",
    "VOCAB_SIZE=50257\n",
    "\n",
    "# Data Paths\n",
    "DATA_OUTPUT_PATH=/dli/megatron/checkpoints/test\n",
    "CHECKPOINT_PATH=/dli/megatron/checkpoints\n",
    "TENSORBOARD_PATH=/dli/megatron/tensorboard\n",
    "LOGS_PATH=/dli/megatron/logs\n",
    "VOCAB_FILE=/dli/data/GPT-2_assets/gpt2-vocab.json\n",
    "MERGE_FILE=/dli/data/GPT-2_assets/gpt2-merges.txt\n",
    "DATA_PATH=/dli/data/GPT-2_assets/my-gpt2_text_document\n",
    "\n",
    "NAME=\"log_2Nodes4GPUS_hybrid\"\n",
    "\n",
    "\n",
    "OPTIMIZER_ARGS=\" \\\n",
    "            --optimizer adam \\\n",
    "            --adam-beta1 0.9 \\\n",
    "            --adam-beta2 0.95 \\\n",
    "            --adam-eps 1e-8 \\\n",
    "            --lr 6e-5 \\\n",
    "            --min-lr 6e-6 \\\n",
    "            --lr-decay-style cosine \\\n",
    "            --lr-decay-iters 800 \\\n",
    "            --lr-warmup-fraction .01 \\\n",
    "            --clip-grad 1.0 \\\n",
    "            --weight-decay 1e-1 \\\n",
    "            --exit-duration-in-mins 1190 \\\n",
    "              \"\n",
    "\n",
    "GPT_ARGS=\" \\\n",
    "            --num-layers $NLAYERS \\\n",
    "            --hidden-size $NHIDDEN \\\n",
    "            --num-attention-heads $NHEADS \\\n",
    "            --seq-length $SEQ_LEN \\\n",
    "            --max-position-embeddings $SEQ_LEN \\\n",
    "            --micro-batch-size $MICRO_BATCH_SIZE \\\n",
    "            --global-batch-size $GLOBAL_BATCH_SIZE \\\n",
    "            --train-iters 100 \\\n",
    "            --vocab-file $VOCAB_FILE \\\n",
    "            --merge-file $MERGE_FILE \\\n",
    "            --init-method-std 0.006 \\\n",
    "            $OPTIMIZER_ARGS \\\n",
    "        \"\n",
    "\n",
    "OUTPUT_ARGS=\" \\\n",
    "            --log-interval 10 \\\n",
    "            --save-interval 300 \\\n",
    "            --eval-interval 1000 \\\n",
    "            --eval-iters 10 \\\n",
    "            --tensorboard-dir $TENSORBOARD_PATH \\\n",
    "            --tensorboard-queue-size 1 \\\n",
    "            --log-timers-to-tensorboard \\\n",
    "            --log-batch-size-to-tensorboard \\\n",
    "            --log-validation-ppl-to-tensorboard \\\n",
    "            --profile-execution True \\\n",
    "            --profile-name TP_PP \\\n",
    "            \"\n",
    "\n",
    "export LAUNCHER=\"python -u -m torch.distributed.launch \\\n",
    "             --nproc_per_node $GPUS_PER_NODE \\\n",
    "             --nnodes $NNODES \\\n",
    "             --master_addr $MASTER_ADDR \\\n",
    "             --master_port $MASTER_PORT \\\n",
    "             \"\n",
    "\n",
    "export CMD=\" \\\n",
    "             /dli/megatron/Megatron-LM/pretrain_gpt.py \\\n",
    "             --tensor-model-parallel-size $TP_SIZE \\\n",
    "             --pipeline-model-parallel-size $PP_SIZE \\\n",
    "             $GPT_ARGS \\\n",
    "             $OUTPUT_ARGS \\\n",
    "             --save $CHECKPOINT_PATH \\\n",
    "             --data-path $DATA_PATH \\\n",
    "             --data-impl mmap \\\n",
    "             --split 949,50,1 \\\n",
    "             --distributed-backend nccl \\\n",
    "           \"\n",
    "\n",
    "clear; srun --jobid $SLURM_JOBID bash -c 'NCCL_DEBUG=INFO  $LAUNCHER --node_rank $SLURM_PROCID $CMD' 2>&1 | tee -a $LOGS_PATH/$NAME.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EadWUCr1EKxw"
   },
   "source": [
    "이제 이전 sbatch 스크립트 [pretrain_gpt_2Node4GPU_hybrid.sh](/dli/code/pretrain_gpt_2Node4GPU_hybrid.sh) 를 실행하여 하이브리드 멀티 노드 실행을 진행합니다. `squeue` 명령어를 사용하여 SLURM 대기열을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "8-mYcAOuEKxw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 12\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "                12  slurmpar dli_2nod    admin  R       0:01      2 slurmnode[1-2]\n"
     ]
    }
   ],
   "source": [
    "# Submit the 2 nodes jobs\n",
    "! sbatch /dli/code/pretrain_gpt_2Node4GPU_hybrid.sh\n",
    "\n",
    "# Check the SLURM queue\n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LRB44NhEKxw"
   },
   "source": [
    "Megatron GPT-3 사전 훈련의 성능을 이해하기 위해, 우리는 실행 중에 생성된 로그를 확인할 수 있습니다.\n",
    "\n",
    "[로그](/dli/megatron/logs/log_2Nodes4GPUS_hybrid.txt)를 확인하면 하이브리드 실행에 대한 전역 크기를 확인할 수 있습니다. 아래 메세지를 확인해주세요.\n",
    "\n",
    "```\n",
    "using world size: 4, data-parallel-size: 1, tensor-model-parallel size: 2, pipeline-model-parallel size: 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ki4XQgJCEKxx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using world size: 4, data-parallel-size: 1, tensor-model-parallel size: 2, pipeline-model-parallel size: 2 \n"
     ]
    }
   ],
   "source": [
    "! grep \"using world size:\" /dli/megatron/logs/log_2Nodes4GPUS_hybrid.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SAnvv12EKxx"
   },
   "source": [
    "훈련 성능과 GPU0 메모리 할당 및 할당 해제 내용을 살펴보겠습니다. 다음과 유사한 그래프가 표시될 것 입니다. \n",
    "<img src=\"images/profiling_hybrid.png\" width=\"950\"/>\n",
    "\n",
    "포워드 패스와 백워드 패스 사이의 일정한 시간 스텝은 얼마입니까? 강사님과 함께 논의해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "-R2ElcvmEKxx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 1] (after 10 iterations) memory (MB) | allocated: 639.3779296875 | max allocated: 5250.76513671875 | reserved: 5478.0 | max reserved: 5478.0\n",
      "[Rank 0] (after 10 iterations) memory (MB) | allocated: 640.3779296875 | max allocated: 5252.76513671875 | reserved: 5490.0 | max reserved: 5490.0\n",
      "[Rank 2] (after 10 iterations) memory (MB) | allocated: 650.646484375 | max allocated: 5344.8046875 | reserved: 5662.0 | max reserved: 5662.0\n",
      " iteration       10/     100 | consumed samples:           40 | elapsed time per iteration (ms): 887.0 | learning rate: 6.000E-05 | global batch size:     4 | lm loss: 1.049753E+01 | loss scale: 1.0 | grad norm: 5.716 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      "[Rank 3] (after 10 iterations) memory (MB) | allocated: 651.771484375 | max allocated: 5345.3046875 | reserved: 5918.0 | max reserved: 5918.0\n",
      " iteration       20/     100 | consumed samples:           80 | elapsed time per iteration (ms): 525.3 | learning rate: 5.997E-05 | global batch size:     4 | lm loss: 9.984283E+00 | loss scale: 1.0 | grad norm: 3.480 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       30/     100 | consumed samples:          120 | elapsed time per iteration (ms): 526.3 | learning rate: 5.990E-05 | global batch size:     4 | lm loss: 9.546626E+00 | loss scale: 1.0 | grad norm: 2.557 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       40/     100 | consumed samples:          160 | elapsed time per iteration (ms): 517.1 | learning rate: 5.978E-05 | global batch size:     4 | lm loss: 9.086359E+00 | loss scale: 1.0 | grad norm: 2.572 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       50/     100 | consumed samples:          200 | elapsed time per iteration (ms): 505.9 | learning rate: 5.963E-05 | global batch size:     4 | lm loss: 8.777303E+00 | loss scale: 1.0 | grad norm: 2.331 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       60/     100 | consumed samples:          240 | elapsed time per iteration (ms): 656.6 | learning rate: 5.943E-05 | global batch size:     4 | lm loss: 8.354745E+00 | loss scale: 1.0 | grad norm: 2.407 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       70/     100 | consumed samples:          280 | elapsed time per iteration (ms): 507.2 | learning rate: 5.919E-05 | global batch size:     4 | lm loss: 8.097967E+00 | loss scale: 1.0 | grad norm: 2.500 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       80/     100 | consumed samples:          320 | elapsed time per iteration (ms): 505.3 | learning rate: 5.891E-05 | global batch size:     4 | lm loss: 7.890447E+00 | loss scale: 1.0 | grad norm: 1.906 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       90/     100 | consumed samples:          360 | elapsed time per iteration (ms): 505.8 | learning rate: 5.858E-05 | global batch size:     4 | lm loss: 7.661854E+00 | loss scale: 1.0 | grad norm: 1.785 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration      100/     100 | consumed samples:          400 | elapsed time per iteration (ms): 506.1 | learning rate: 5.822E-05 | global batch size:     4 | lm loss: 7.512233E+00 | loss scale: 1.0 | grad norm: 1.383 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      "saving checkpoint at iteration     100 to /dli/megatron/checkpoints\n",
      "  successfully saved checkpoint at iteration     100 to /dli/megatron/checkpoints\n"
     ]
    }
   ],
   "source": [
    "! grep iteration /dli/megatron/logs/log_2Nodes4GPUS_hybrid.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxsCajThEKxx"
   },
   "source": [
    "좋습니다. 다음으로 넘어가기 전에 이전 실행에서 생성된 불필요한 체크포인트를 삭제하여 디스크 공간을 확보해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Cjlb8wbmEKxx"
   },
   "outputs": [],
   "source": [
    "# Clean the checkpoints \n",
    "! rm -rf /dli/megatron/checkpoints/* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DIiXkq0EKxx"
   },
   "source": [
    "---\n",
    "<h2 style=\"color:green;\">축하합니다!</h2>\n",
    "\n",
    "다음으로 넘어가기 전에 대기열에서 실행 중이거나 대기 중인 작업이 없는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "GnHAGCBQEKxy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n"
     ]
    }
   ],
   "source": [
    "# Check the SLURM jobs queue \n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVOa8C4wEKxy"
   },
   "source": [
    "아직 실행 중이거나 보류 중인 작업이 있는 경우 다음 셀을 실행하여 `scancel` 명령을 사용하여 모든 작업을 취소합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "__0FXHYIEKxy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n"
     ]
    }
   ],
   "source": [
    "# Cancel admin user jobs\n",
    "! scancel -u $USER\n",
    "\n",
    "# Check again the SLURM jobs queue (should be either empty, or the status TS column should be CG)\n",
    "! squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TY-G1knxEKxy"
   },
   "source": [
    "다음으로, 혼합 정밀도, 그래디언트 누적 및 활성화 체크포인팅과 같은 기술을 사용하여 GPT 사전 훈련을 최적화하는 방법에 대해 알아보겠습니다. [004_GPT_LM_pretrainings_optimizations.ipynb](04_GPT_LM_pretrainings_optimizations.ipynb)로 이동합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "03_GPT_LM_pretrainings_multinodes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
