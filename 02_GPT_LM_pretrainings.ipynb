{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWxiOKZ5Dilt"
   },
   "source": [
    "<img src=\"./images/DLI_Header.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VN5x6pSDilz"
   },
   "source": [
    "# 2.0 멀티-GPU 훈련 전략\n",
    "이번 실습 노트북에서는 트랜스포머 기반 언어 모델을 훈련하기 위해  [Megatron-LM](https://github.com/NVIDIA/Megatron-LM) NVIDIA 라이브러리를 사용한 분산 학습 전략 및 실험에 대한 기본 지식을 소개합니다.\n",
    "\n",
    "\n",
    "### 학습 목표\n",
    "\n",
    "이번 실습 노트북의 목표는 다음과 같습니다. |\n",
    "* 분산 훈련 전략의 메커니즘 이해하기\n",
    "* 데이터와 텐서 병렬 분산을 적용하여 1 노드에서 Megatron-LM 스크립트를 사용하여 간단한 분산 학습을 실행하기\n",
    "* Megatron-LM 로그의 기본 출력 값을 이해하기\n",
    "\n",
    "\n",
    "**[2.1 분산 학습 전략 소개](#1.1-The-hardware-overview)<br>**\n",
    "**[2.2 Megatron-LM GPT 사전훈련을 활용한 단일 GPU 학습 실행](#1.1-The-hardware-overview)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.2.1 GPT 사전 훈련 스크립트 체크하기](#1.2.1-Exercise:-Explore-the-Test-Set)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.2.1 GPU 사전 훈련 스크립트 실행하기](#1.2.1-Exercise:-Explore-the-Test-Set)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.2.3 Megatron-LM 실행 로그 이해하기](#1.2.1-Exercise:-Explore-the-Test-Set)<br>\n",
    "**[2.3 Megatron-LM GPT 사전훈련을 활용한 멀티 GPU 학습 실행](#1.2-The-SLURM-Cluster-overview)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.3.1 연습: 2 GPU에서 Megatron-LM GPT 사전 훈련 실행](#1.2.1-Exercise:-Explore-the-Test-Set)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.3.2 멀티-GPU Megatron-LM 실행 로그 이해하기](#1.2.1-Exercise:-Explore-the-Test-Set)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.3.3 모델 분산 시 고려할 점](#1.2.1-Exercise:-Explore-the-Test-Set)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQn0drXCDil0"
   },
   "source": [
    "### 이전 실행/보류 중인 작업을 취소합니다.\n",
    "\n",
    "다음으로 이동하기 전에 SLURM 대기열에서 아직 실행 중이거나 대기 중인 작업이 없는지 확인하십시오. 다음 셀을 실행하여 SLURM 작업 대기열을 확인합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EnzhDlTWDil1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n"
     ]
    }
   ],
   "source": [
    "# Check the SLURM jobs queue \n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUlmEbuHDil3"
   },
   "source": [
    "여전히 실행 중이거나 보류 중인 작업이 있는 경우 다음 셀을 실행하여 `scancel` 명령어를 사용하여 모든 사용자의 작업을 취소합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AkU69x69Dil4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n"
     ]
    }
   ],
   "source": [
    "# Cancel admin user jobs\n",
    "! scancel -u $USER\n",
    "\n",
    "# Check again the SLURM jobs queue (should be either empty, or the status TS column should be CG)\n",
    "! squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atfFvPU3Dil5"
   },
   "source": [
    "---\n",
    "# 2.1 분산 학습 전략 소개\n",
    "분산 학습 모드에서는 훈련 프로세스를 분할하는 것이 목표입니다. ---\n",
    "# 2.1 분산 학습 전략 소개\n",
    "분산 학습 모드에서 목표는 여러 기기에 걸쳐 훈련 프로세스를 분할하는 것입니다. 가장 일반적으로 사용되는 분산 전략은 **데이터* 및 **모델** 병렬화입니다.\n",
    "\n",
    "\n",
    "## 데이터 분산 (Data Distribution)\n",
    "\n",
    "신경망은 일반적으로 [Stochastic Gradient Descent - 확률적 경사 하강법](https://developer.nvidia.com/blog/a-data-scientists-guide-to-gradient-descent-and-backpropagation-algorithms/) 을 사용하여 순차적으로 처리되는 배치로 분할하는 방식으로 구성됩니다. 순방향 단계에서는 피쳐 맵이 계산되고 역방향 패스에서는 그레디언트가 계산되고 평균화되어 파라미터 업데이트가 결정됩니다. 마지막으로 모델의 매개 변수가 업데이트되면 다음 데이터 배치가 처리됩니다.\n",
    "\n",
    "<img src=\"images/data_parallel.png\" width=\"600\"/>\n",
    "\n",
    "데이터 병렬 모드에서 데이터는 여러 기기에 걸쳐 분할되며, 각 기기는 각 시스템에 의해 호스팅되는 동일한 신경망의 복사본에 의해 처리됩니다. 매개 변수 업데이트는 모든 기기에서 평균화되고 모델 업데이트는 모든 복사본에 반영됩니다.\n",
    "\n",
    "더 많은 프로세서 (또는 더 높은 데이터 병렬화)를 사용하면 에폭(즉, 전체 데이터 세트) 시간이 줄어들기 때문에, 이는 학습 속도를 높이는 효과가 있습니다. 또한 업데이트된 그레디언트는 (글로벌 배치 크기 증가로 인해) 더 많은 수의 표본을 효과적으로 확인되기 때문에 수렴 시간에 긍정적인 영향을 미칩니다. 배치당 걸리는 시간은 그레디언트 교환 통신 비용이 추가되어 여전히 동일합니다. \n",
    "\n",
    "그레디언트 교환을 구현하기 위해서는 다양한 전략이 있습니다. \n",
    "- **Centralized** 방식으로 서버 시스템이 데이터 청크를 배포하고 그레디언트를 누적하며 모델 매개 변수를 업데이트합니다. \n",
    "- **Decentralized** 방식으로, 각 워커가 다른 워커로부터 그레디언트를 보내고 수집하여 모델의 매개 변수를 로컬로 집계하고 업데이트합니다. 또한 워커들은 서로 다른 속도로 연산을 수행할 수 있습니다. 따라서 모델 매개 변수는 워커의 동기화 포인트를 기반으로 동기식으로 업데이트할 수 있습니다. 또한 워커가 오래된 매개 변수를 사용하여 작업할 수 있도록 여유 있는 전략을 사용할 수 있습니다. 이 전략은 훈련 중에 불일치를 초래할 수도 있습니다.\n",
    "\n",
    "여러 라이브러리는 데이터 병렬화 구현을 제공하며, 대표적인 예로 [Horovod](https://github.com/horovod/horovod)가 있습니다. Horovod는 TensorFlow, Keras, PyTorch, Apache MXNet 과 같은 여러 딥 러닝 프레임워크와 호환됩니다. NVIDIA APEX](https://nvidia.github.io/apex/)는 분산 학습 및 혼합 정밀도를 간소화하는 유틸리티를 제공하는 Pytorch 확장 라이브러리입니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 모델 분산 전략\n",
    "\n",
    "모델 병렬화는 여러 기기에 걸쳐 모델의 매개 변수를 분할하는 프로세스입니다. 이를 통해 피쳐 맵 교환으로 인한 추가 통신 비용으로 1개의 GPU에 맞지 않는 더 큰 모델을 학습할 수 있습니다. \n",
    "\n",
    "두 가지 유형의 모델 분산를 구별할 수 있습니다.\n",
    "\n",
    "### 파이프라인 병렬화\n",
    "\n",
    "\n",
    "<img src=\"images/pipeline_parallel1.png\" width=\"600\"/>\n",
    "\n",
    "파이프라인 병렬화는 모델을 조각으로 순차적으로 잘라내고 각 부분을 특정 워커에게 할당하는 프로세스입니다. 예를 들어 device_1의 레이어 1,2와 device_2의 레이어 3,4 등이 있습니다. \n",
    "\n",
    "마이크로배치 파이프라인 병렬화 [GPipe](https://arxiv.org/pdf/1811.06965.pdf) 와 같은 다양한 파이프라인 전략이 있으며, GPipe는 기기가 다른 피어들이 출력을 통신하기를 기다리는 시간을 최소화하기 위해 사용되는 모델 파이프라이닝 최적화된 구현 방식입니다. 데이터 청크를 마이크로 배치로 분할하여 서로 다른 시스템이 서로 다른 마이크로 배치를 동시에 처리할 수 있도록 합니다.\n",
    "\n",
    "![title](images/pipeline_parallel.png)\n",
    "\n",
    "[Interleaved pipeline parallelism](https://github.com/NVIDIA/Megatron-LM/)은 장치당 하나의 순차적 레이어 집합 대신 각각 계산량이 적은 여러 개의 파이프라인 단계를 할당합니다. \n",
    "예를 들어 device_1의 레이어 1, 2, 9,10, device_2의 레이어 3, 4, 11,12 등이 있습니다. \n",
    "\n",
    "\n",
    "### 텐서 병렬화\n",
    "\n",
    "<img src=\"images/tensor_parallel1.png\" width=\"500\"/>\n",
    "\n",
    "텐서 병렬화는  워커들 간에 행렬 연산을 나누는 과정입니다. [Megatron-LM](https://github.com/NVIDIA/Megatron-LM/) 은 NVIDIA의 오픈 소스 라이브러리로, 혼합 정밀도를 사용하여 트랜스포머 기반 네트워크의 효율적인 학습 및 GPT, BERT, T5와 같은 트랜스포머 기반 모델의 멀티 노드 사전 훈련을 제공합니다. Megatron의 트랜스포머 구현에서 셀프 어텐션 및 MLP 연산은 트랜스포머 셀당 총 4개의 All-Reduce 연산으로 병렬 블록으로 나뉩니다 (포워드 패스에 2개, 백워드 패스에 2개).\n",
    "\n",
    "<img src=\"images/tensor_parallel.png\" width=\"250\"/>\n",
    "\n",
    "Megatron-LM 은 PyTorch 위에 구축되며 혼합 정밀도를 사용하여 GPT 및 BERT 변압기 아키텍처의 사전 훈련을 위해 데이터, 파이프라인 및 텐서 병렬화를 통합합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bw2wRTG_Dil9"
   },
   "source": [
    "---\n",
    "# 2.2 Megatron-LM GPT 사전 훈련의 단일 GPU 훈련 실행 \n",
    "\n",
    "먼저 간단한 Megatron-LM GPT 실행 스크립트를 살펴보겠습니다.\n",
    "\n",
    "분산 학습 모드의 경우 스크립트는 [PyTorch distributed launcher](https://pytorch.org/docs/stable/distributed.html)를 사용합니다. PyTorch 분산 모듈은 Python 플래그 `-m torch.distributed.launch` 함께 사용됩니다. \n",
    "\n",
    "리소스는`--nnodes` 및`--nproc_per_node`  인자로 구성되어 노드 수 및 노드 당 사용할 GPU 수를 각각 지정합니다.\n",
    "\n",
    "Megatron-LM 라이브러리를 사용하면 두 가지 유형의 분산 데이터 병렬 구현이 가능합니다. \n",
    "- `local` 은 백 프롭(back propagation) 단계 끝에에서 그래디언트 올-리듀스(gradient all-reduce)를 수행합니다. \n",
    "- `torch` 는 그래디언트 감소 연산과 백 프롭 연산(더 큰 모델 크기에서는 더 효율적임)을 겹치는 분산 데이터 병렬 래퍼입니다.\n",
    "\n",
    "이 섹션에서는 해당 인자를 사용하여 Megatron-LM pretrain_gpt.py 스크립트를 실행하여 1 GPU에서 간단한 Megatron-LM GPT 사전 훈련 실행문을 돌려봅니다.\n",
    "\n",
    "\n",
    "<img src=\"images/Megatron_run.PNG\" width=\"600\"/>\n",
    "우리는  `--DDP-impl` 인자를 사용하여 분산 데이터 병렬 구현을 지정할 수 있습니다.\n",
    "\n",
    "분산 전략은 `--tensor-model-parallel-size` 및 `--pipeline-model-parallel-size` 인자를 사용하여 구성됩니다.\n",
    "[Megatron-LM 설명서](https://github.com/NVIDIA/Megatron-LM#distributed-pretraining)에서 분산 전략들에 대해 자세히 알아보십시오.\n",
    "\n",
    "우리는 (배포 전략이 적용되지 않은) 1개의 GPU에서만 GPT 사전 훈련을 실행할 스크립트  [pretrain_gpt_1GPU.sh](/dli/code/pretrain_gpt_1GPU.sh) 를 준비했습니다.\n",
    "\n",
    "이 스크립트는 연산 리소스가 이미 할당되었다고 가정합니다. 따라서 실행을 위해 먼저 대화형 세션에서 워커 노드에 연결하여 필요한 GPU를 할당해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvRqhqSNDil-"
   },
   "source": [
    "## 2.2.1 GPT 사전 훈련 스크립트 확인\n",
    "\n",
    "리소스를 할당하고 실행하기 전에 스크립트를 살펴보겠습니다. \n",
    "\n",
    "모델 아키텍처 및 트레이닝 인자에 주목하십시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yhTZI5pxDil_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "# Distributed training args\n",
      "NNODES=1\n",
      "GPUS_PER_NODE=1\n",
      "TP_SIZE=1\n",
      "PP_SIZE=1\n",
      "\n",
      "# Distributed training \n",
      "MICRO_BATCH_SIZE=2\n",
      "GLOBAL_BATCH_SIZE=2\n",
      "\n",
      "# Model architecture \n",
      "NLAYERS=12\n",
      "NHIDDEN=768\n",
      "NHEADS=32\n",
      "SEQ_LEN=1024\n",
      "VOCAB_SIZE=50257\n",
      "\n",
      "# Data Paths\n",
      "VOCAB_FILE=/dli/data/GPT-2_assets/gpt2-vocab.json\n",
      "MERGE_FILE=/dli/data/GPT-2_assets/gpt2-merges.txt\n",
      "DATA_PATH=/dli/data/GPT-2_assets/my-gpt2_text_document\n",
      "\n",
      "DATA_OUTPUT_PATH=/dli/megatron/checkpoints/test\n",
      "CHECKPOINT_PATH=/dli/megatron/checkpoints\n",
      "TENSORBOARD_PATH=/dli/megatron/tensorboard\n",
      "LOGS_PATH=/dli/megatron/logs\n",
      "NAME=\"log_1GPU\"\n",
      "\n",
      "# SLURM args\n",
      "MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)\n",
      "MASTER_PORT=6000\n",
      "\n",
      "\n",
      "OPTIMIZER_ARGS=\" \\\n",
      "            --optimizer adam \\\n",
      "            --adam-beta1 0.9 \\\n",
      "            --adam-beta2 0.95 \\\n",
      "            --adam-eps 1e-8 \\\n",
      "            --lr 6e-5 \\\n",
      "            --min-lr 6e-6 \\\n",
      "            --lr-decay-style cosine \\\n",
      "            --lr-decay-iters 800 \\\n",
      "            --lr-warmup-fraction .01 \\\n",
      "            --clip-grad 1.0 \\\n",
      "            --weight-decay 1e-1 \\\n",
      "            --exit-duration-in-mins 1190 \\\n",
      "              \"\n",
      "\n",
      "GPT_ARGS=\" \\\n",
      "            --num-layers $NLAYERS \\\n",
      "            --hidden-size $NHIDDEN \\\n",
      "            --num-attention-heads $NHEADS \\\n",
      "            --seq-length $SEQ_LEN \\\n",
      "            --max-position-embeddings $SEQ_LEN \\\n",
      "            --micro-batch-size $MICRO_BATCH_SIZE \\\n",
      "            --global-batch-size $GLOBAL_BATCH_SIZE \\\n",
      "            --train-iters 100 \\\n",
      "            --vocab-file $VOCAB_FILE \\\n",
      "            --merge-file $MERGE_FILE \\\n",
      "            --init-method-std 0.006 \\\n",
      "            $OPTIMIZER_ARGS \\\n",
      "            $EXIT_OPTS \\\n",
      "        \"\n",
      "\n",
      "OUTPUT_ARGS=\" \\\n",
      "            --log-interval 10 \\\n",
      "            --save-interval 300 \\\n",
      "            --eval-interval 1000 \\\n",
      "            --eval-iters 10 \\\n",
      "            --tensorboard-dir $TENSORBOARD_PATH \\\n",
      "            --tensorboard-queue-size 1 \\\n",
      "            --log-timers-to-tensorboard \\\n",
      "            --log-batch-size-to-tensorboard \\\n",
      "            --log-validation-ppl-to-tensorboard \\\n",
      "            \"\n",
      "\n",
      "\n",
      "export LAUNCHER=\"python -u -m torch.distributed.launch \\\n",
      "            --nproc_per_node $GPUS_PER_NODE \\\n",
      "            --nnodes $NNODES \\\n",
      "            --master_addr $MASTER_ADDR \\\n",
      "            --master_port $MASTER_PORT \\\n",
      "            \"\n",
      "\n",
      "export CMD=\" \\\n",
      "            /dli/megatron/Megatron-LM/pretrain_gpt.py \\\n",
      "            --tensor-model-parallel-size $TP_SIZE \\\n",
      "            --pipeline-model-parallel-size $PP_SIZE \\\n",
      "            $GPT_ARGS \\\n",
      "            $OUTPUT_ARGS \\\n",
      "            --save $CHECKPOINT_PATH \\\n",
      "            --data-path $DATA_PATH \\\n",
      "            --data-impl mmap \\\n",
      "            --split 949,50,1 \\\n",
      "            --distributed-backend nccl \\\n",
      "            \"\n",
      "\n",
      "bash -c '$LAUNCHER  $CMD' 2>&1 | tee -a $LOGS_PATH/$NAME.txt\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the Megaton-LM GPT pretraining execution on 1 GPU script\n",
    "! cat /dli/code/pretrain_gpt_1GPU.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WU4W4uSrDimA"
   },
   "source": [
    "## 2.2.2 GPT 사전 훈련 스크립트 실행\n",
    "\n",
    "이제 대화형 세션에서 pretrain_gpt_1GPU.sh 스크립트를 실행해 보겠습니다. 실행을 위해서는 다음 3 단계를 따르십시오.\n",
    "1. 터미널 세션을 시작합니다.\n",
    "2. srun -N 1 --pty /bin/bash`를 실행하여 대화형 세션을 실행합니다.\n",
    "3.`bash ./code/pretrain_gpt_1GPU.sh`를 실행하여 1개의 GPU에서 Megatron GPT-3 사전훈련을 실행합니다.\n",
    "\n",
    "\n",
    "<img src=\"images/interactive_launch0.png\" width=\"1050\"/>\n",
    "\n",
    "다음 셀을 실행하여 터미널 세션을 여는 링크와 대화형 세션을 실행하는 지침을 생성합니다. 그런 다음 1개의 GPU에서 GPT 사전 훈련 작업을 제출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7ahDwcspDimB"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<pre>\n",
       "   Step 1: Open a terminal session by following the <a href=\"\", data-commandlinker-command=\"terminal:create-new\">Terminal link</a>\n",
       "   Step 2: Run an interactive session: <font color=\"green\">srun -N 1 --pty /bin/bash</font>\n",
       "   Step 3: Run the megatron gpt3 pretraining on 1 GPU: <font color=\"green\">bash ./code/pretrain_gpt_1GPU.sh</font>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<pre>\n",
    "   Step 1: Open a terminal session by following the <a href=\"\", data-commandlinker-command=\"terminal:create-new\">Terminal link</a>\n",
    "   Step 2: Run an interactive session: <font color=\"green\">srun -N 1 --pty /bin/bash</font>\n",
    "   Step 3: Run the megatron gpt3 pretraining on 1 GPU: <font color=\"green\">bash ./code/pretrain_gpt_1GPU.sh</font>\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjWlL-kzDimC"
   },
   "source": [
    "GPU 1개에 대한 GPT 사전 훈련이 실행되는 동안, 다음 셀을 실행하여 SLURM 대기열을 확인할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PvCGgr_6DimD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "                 7  slurmpar     bash    admin  R      17:50      1 slurmnode1\n"
     ]
    }
   ],
   "source": [
    "# Check the SLURM queue\n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2raUABHtDimE"
   },
   "source": [
    "`nvidia-smi` 명령을 사용하여 GPU를 확인할 수도 있습니다. 아래 그림과 같이 GPU 0만 활용되고 있습니다. Megatron-LM을 처음 실행할 때는 코드를 컴파일하는 데 약 6분이 소요됩니다. 그 때까지는 GPU 활동을 볼 수 없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yihAwJzuDimE"
   },
   "source": [
    "<img src=\"images/1N_1gpu_utilization.png\" width=\"650\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4PoYFWRQDimF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Fri Mar 28 02:03:25 2025       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1B.0 Off |                    0 |\n",
      "| N/A   33C    P0    36W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   33C    P0    37W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:00:1D.0 Off |                    0 |\n",
      "| N/A   34C    P0    39W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   33C    P0    38W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check GPU utilization on the master node after Megatron-LM is compiled\n",
    "! sleep 6m\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moZHM-gwDimG"
   },
   "source": [
    "## 2.2.3 Megatron-LM 실행 로그 이해\n",
    "\n",
    "pretrain_gpt_1GPU.sh 스크립트에 지정된 대로 Megatron-LM이 실행되는 월드 크기는 다음과 같아야 합니다.\n",
    "\n",
    "```\n",
    "using world size: 1, data-parallel-size: 1, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXsNjraaDimG"
   },
   "source": [
    "![title](images/interactive_launch1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBIWt_lrDimH"
   },
   "source": [
    "GPT 사전 훈련의 성능을 이해하기 위해 실행 중에 생성된 [로그](./megatron/logs/log_1GPU.txt)를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OyclKEuqDimH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " iteration       10/     100 | consumed samples:           20 | elapsed time per iteration (ms): 448.0 | learning rate: 6.000E-05 | global batch size:     2 | lm loss: 1.052843E+01 | loss scale: 1.0 | grad norm: 3.027 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      "[Rank 0] (after 10 iterations) memory (MB) | allocated: 1907.2294921875 | max allocated: 10582.0205078125 | reserved: 10922.0 | max reserved: 10922.0\n",
      " iteration       20/     100 | consumed samples:           40 | elapsed time per iteration (ms): 273.6 | learning rate: 5.997E-05 | global batch size:     2 | lm loss: 1.004032E+01 | loss scale: 1.0 | grad norm: 3.089 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       30/     100 | consumed samples:           60 | elapsed time per iteration (ms): 273.8 | learning rate: 5.990E-05 | global batch size:     2 | lm loss: 9.632593E+00 | loss scale: 1.0 | grad norm: 2.586 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       40/     100 | consumed samples:           80 | elapsed time per iteration (ms): 273.6 | learning rate: 5.978E-05 | global batch size:     2 | lm loss: 9.126163E+00 | loss scale: 1.0 | grad norm: 2.613 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       50/     100 | consumed samples:          100 | elapsed time per iteration (ms): 273.7 | learning rate: 5.963E-05 | global batch size:     2 | lm loss: 8.792195E+00 | loss scale: 1.0 | grad norm: 2.598 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       60/     100 | consumed samples:          120 | elapsed time per iteration (ms): 273.7 | learning rate: 5.943E-05 | global batch size:     2 | lm loss: 8.457767E+00 | loss scale: 1.0 | grad norm: 2.508 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       70/     100 | consumed samples:          140 | elapsed time per iteration (ms): 273.4 | learning rate: 5.919E-05 | global batch size:     2 | lm loss: 8.082476E+00 | loss scale: 1.0 | grad norm: 2.201 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       80/     100 | consumed samples:          160 | elapsed time per iteration (ms): 273.7 | learning rate: 5.891E-05 | global batch size:     2 | lm loss: 7.830711E+00 | loss scale: 1.0 | grad norm: 2.224 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       90/     100 | consumed samples:          180 | elapsed time per iteration (ms): 273.5 | learning rate: 5.858E-05 | global batch size:     2 | lm loss: 7.871712E+00 | loss scale: 1.0 | grad norm: 1.844 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration      100/     100 | consumed samples:          200 | elapsed time per iteration (ms): 273.7 | learning rate: 5.822E-05 | global batch size:     2 | lm loss: 7.587920E+00 | loss scale: 1.0 | grad norm: 1.468 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      "saving checkpoint at iteration     100 to /dli/megatron/checkpoints\n",
      "  successfully saved checkpoint at iteration     100 to /dli/megatron/checkpoints\n"
     ]
    }
   ],
   "source": [
    "# Check the Megatron GPT3 pretraining logs.\n",
    "! grep iteration /dli/megatron/logs/log_1GPU.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0htcvuK9DimI"
   },
   "source": [
    "추출에서 출력은 다음과 유사해야 합니다.\n",
    "\n",
    "```\n",
    " iteration      100/     100 | consumed samples:          200 | elapsed time per iteration (ms): 271.6 | learning rate: 5.822E-05 | global batch size:     2 | lm loss: 7.587920E+00 | loss scale: 1.0 | grad norm: 1.468 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
    "```   \n",
    "\n",
    "이번 예제에서는 (글로벌 배치 크기) 2개의 샘플을 처리하는 데 271.6ms의 학습 속도가 소요되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LFy7sI6DimJ"
   },
   "source": [
    "좋습니다. 다음으로 넘어가기 전에 이전 실행에서 생성된 불필요한 체크포인트를 삭제하여 디스크 공간을 확보하고 나머지 대화형 세션을 취소해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kd3l_uVBDimK"
   },
   "outputs": [],
   "source": [
    "# Clean the checkpoints \n",
    "! rm -rf /dli/megatron/checkpoints/*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSqY1y6kDimL"
   },
   "source": [
    "----\n",
    "\n",
    "# 2.3 Megatron-LM GPT 사전 훈련의 멀티 GPU 훈련 실행\n",
    "\n",
    "이제 대화형 세션에서 사용할 수 있는 2개의 GPU를 활용하여 동일한 이전 훈련 작업을 실행해 보겠습니다. \n",
    "\n",
    "`torch.distributed.launch`를 사용하여 2개의 GPU에서 작업을 시작하면 노드당 프로세스 수를 `--nproc_per_node 2`로 설정해야 합니다. \n",
    "\n",
    "우리가 실험할 첫 번째 분산 전략은 데이터 병렬 분산 전략으로, 여러 리소스가 사용 가능할 때 기본적으로 Megatron-LM 으로 실행됩니다.\n",
    "             \n",
    "단일 GPU에서 이전에 실행된 경우, GPU에 의해 처리된 배치 크기는 2(`--micro-batch-size`에 의해 설정됨)였으며, 이는 글로벌 배치 크기(`--global-batch-size`)에도 해당합니다. \n",
    "\n",
    "\n",
    "## 2.3.1 연습: 2개의 GPU에서 Megatron-LM GPT 사전 훈련 실행\n",
    "\n",
    "다음 셀의 \"FIXME\"를 수정하여 데이터 병렬 분산을 사용하여 2개의 GPU에서 새로운 Megatron-LM GPT 사전 훈련 실행을 구성해 보겠습니다. \n",
    "\n",
    "2개의 GPU를 사용하려면 GPU당 마이크로 배치 크기를 2로 유지하고 글로벌 배치 크기를 4로 2배 늘리면 됩니다. 막히면 언제든지 [솔루션](solutions/ex2.3.ipynb)을 확인하십시오.\n",
    "\n",
    "각 실행마다 로그 파일 이름(이번 예제에서는 *log_2GPU.txt*)을 변경하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FsZRcjMUDimL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /dli/code/pretrain_gpt_2GPU.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile /dli/code/pretrain_gpt_2GPU.sh\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "# Distributed training args\n",
    "NNODES=1\n",
    "GPUS_PER_NODE=2\n",
    "TP_SIZE=1\n",
    "PP_SIZE=1\n",
    "\n",
    "# Distributed training \n",
    "MICRO_BATCH_SIZE=2\n",
    "GLOBAL_BATCH_SIZE=4\n",
    "\n",
    "# Model architecture \n",
    "NLAYERS=12\n",
    "NHIDDEN=768\n",
    "NHEADS=32\n",
    "SEQ_LEN=1024\n",
    "VOCAB_SIZE=50257\n",
    "\n",
    "# Data Paths\n",
    "VOCAB_FILE=/dli/data/GPT-2_assets/gpt2-vocab.json\n",
    "MERGE_FILE=/dli/data/GPT-2_assets/gpt2-merges.txt\n",
    "DATA_PATH=/dli/data/GPT-2_assets/my-gpt2_text_document\n",
    "\n",
    "DATA_OUTPUT_PATH=/dli/megatron/checkpoints/test\n",
    "CHECKPOINT_PATH=/dli/megatron/checkpoints\n",
    "TENSORBOARD_PATH=/dli/megatron/tensorboard\n",
    "LOGS_PATH=/dli/megatron/logs\n",
    "NAME=\"log_2GPU\"        \n",
    "\n",
    "# SLURM args\n",
    "MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)\n",
    "MASTER_PORT=6000\n",
    "\n",
    "\n",
    "OPTIMIZER_ARGS=\" \\\n",
    "            --optimizer adam \\\n",
    "            --adam-beta1 0.9 \\\n",
    "            --adam-beta2 0.95 \\\n",
    "            --adam-eps 1e-8 \\\n",
    "            --lr 6e-5 \\\n",
    "            --min-lr 6e-6 \\\n",
    "            --lr-decay-style cosine \\\n",
    "            --lr-decay-iters 800 \\\n",
    "            --lr-warmup-fraction .01 \\\n",
    "            --clip-grad 1.0 \\\n",
    "            --weight-decay 1e-1 \\\n",
    "            --exit-duration-in-mins 1190 \\\n",
    "            \"\n",
    "\n",
    "GPT_ARGS=\" \\\n",
    "            --num-layers $NLAYERS \\\n",
    "            --hidden-size $NHIDDEN \\\n",
    "            --num-attention-heads $NHEADS \\\n",
    "            --seq-length $SEQ_LEN \\\n",
    "            --max-position-embeddings $SEQ_LEN \\\n",
    "            --micro-batch-size $MICRO_BATCH_SIZE \\\n",
    "            --global-batch-size $GLOBAL_BATCH_SIZE \\\n",
    "            --train-iters 100 \\\n",
    "            --vocab-file $VOCAB_FILE \\\n",
    "            --merge-file $MERGE_FILE \\\n",
    "            --init-method-std 0.006 \\\n",
    "            $OPTIMIZER_ARGS \\\n",
    "            $EXIT_OPTS \\\n",
    "            \"\n",
    "\n",
    "OUTPUT_ARGS=\" \\\n",
    "            --log-interval 10 \\\n",
    "            --save-interval 300 \\\n",
    "            --eval-interval 1000 \\\n",
    "            --eval-iters 10 \\\n",
    "            --tensorboard-dir $TENSORBOARD_PATH \\\n",
    "            --tensorboard-queue-size 1 \\\n",
    "            --log-timers-to-tensorboard \\\n",
    "            --log-batch-size-to-tensorboard \\\n",
    "            --log-validation-ppl-to-tensorboard \\\n",
    "            \"\n",
    "export LAUNCHER=\"python -u -m torch.distributed.launch \\\n",
    "            --nproc_per_node $GPUS_PER_NODE \\\n",
    "            --nnodes $NNODES \\\n",
    "            --master_addr $MASTER_ADDR \\\n",
    "            --master_port $MASTER_PORT \\\n",
    "            \"\n",
    "\n",
    "export CMD=\" \\\n",
    "            /dli/megatron/Megatron-LM/pretrain_gpt.py \\\n",
    "            --tensor-model-parallel-size $TP_SIZE \\\n",
    "            --pipeline-model-parallel-size $PP_SIZE \\\n",
    "            $GPT_ARGS \\\n",
    "            $OUTPUT_ARGS \\\n",
    "            --save $CHECKPOINT_PATH \\\n",
    "            --data-path $DATA_PATH \\\n",
    "            --data-impl mmap \\\n",
    "            --split 949,50,1 \\\n",
    "            --distributed-backend nccl \\\n",
    "            \"\n",
    "\n",
    "bash -c '$LAUNCHER  $CMD' 2>&1 | tee -a $LOGS_PATH/$NAME.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zVWaEf-DimN"
   },
   "source": [
    "이제 대화형 세션에서 이 스크립트를 실행합니다. 실행을 위해서는 다음 3단계를 따르십시오.\n",
    "1. 터미널 세션을 시작합니다.\n",
    "2. `srun -N 1 --pty /bin/bash`를 실행하여 대화형 세션을 실행합니다.\n",
    "3.`bash ./code/pretrain_gpt_2GPU.sh`를 실행하여 1개의 GPU에서 megatron gpt3 사전 훈련을 실행합니다.\n",
    "\n",
    "다음 셀을 실행하여 터미널 세션을 여는 링크와 대화형 세션을 실행하는 지침을 가져옵니다. 이후에 2개의 GPU에서 사전 훈련 작업을 제출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CwRCw8zKDimN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<pre>\n",
       "   Step 1: Open a terminal session by following the <a href=\"\", data-commandlinker-command=\"terminal:create-new\">Terminal link</a>\n",
       "   Step 2: Run an interactive session: <font color=\"green\">srun -N 1 --pty /bin/bash</font>\n",
       "   Step 3: Run the megatron gpt3 pretraining on 1 GPU: <font color=\"green\">bash ./code/pretrain_gpt_2GPU.sh</font>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<pre>\n",
    "   Step 1: Open a terminal session by following the <a href=\"\", data-commandlinker-command=\"terminal:create-new\">Terminal link</a>\n",
    "   Step 2: Run an interactive session: <font color=\"green\">srun -N 1 --pty /bin/bash</font>\n",
    "   Step 3: Run the megatron gpt3 pretraining on 1 GPU: <font color=\"green\">bash ./code/pretrain_gpt_2GPU.sh</font>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZI1ToVUDimO"
   },
   "source": [
    "노드 1개에서 GPU 2개에 대한 GPT 사전 훈련이 실행되는 동안, 우리는 SLURM 대기열을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "P7WqcNyyDimO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "                 7  slurmpar     bash    admin  R      26:06      1 slurmnode1\n",
      "                 8  slurmpar     bash    admin  R       1:52      1 slurmnode1\n"
     ]
    }
   ],
   "source": [
    "# Check the SLURM queue\n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXixTWGyDimO"
   },
   "source": [
    "`nvidia-smi` 명령을 사용하여 GPU 활용 현황을 확인할 수도 있습니다. 아래 그림과 같이 GPU 0과 1이 활용되는 것을 볼 수 있습니다.\n",
    "\n",
    "<img src=\"images/1N_2gpus_utilization.png\" width=\"650\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "t9I9NuJ9DimP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 28 02:11:14 2025       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1B.0 Off |                    0 |\n",
      "| N/A   42C    P0   272W / 300W |  12112MiB / 16160MiB |     79%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   42C    P0   120W / 300W |  12112MiB / 16160MiB |     99%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:00:1D.0 Off |                    0 |\n",
      "| N/A   34C    P0    39W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   34C    P0    39W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check GPU utilization on the master node\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2FA-RU1DimP"
   },
   "source": [
    "## 2.3.2 멀티 GPU Megatron-LM 실행 로그 이해하기\n",
    "\n",
    "실행 로그를 살펴보겠습니다.\n",
    "\n",
    "<img src=\"images/interactive_launch2.png\" width=\"900\"/>\n",
    "\n",
    "Megatron-LM이 실행할 월드 크기는 다음과 같습니다. \n",
    "\n",
    "```\n",
    "world size: 2, data-parallel-size: 2, tensor-model-parallel size: 1, pipeline-model-parallel size: 1\n",
    "```\n",
    "\n",
    "2개의 GPU를 사용할 수 있기 때문에 기본적으로 실행되는 분산 전략은 데이터 병렬 전략입니다. 즉, 모델은 두 GPU에 복사되어 서로 다른 데이터 배치를 처리합니다. \n",
    "\n",
    "2개의 GPU에 대한 GPT 사전 훈련의 성능을 이해하기 위해, 우리는 실행 중에 생성된 [로그 파일](/dli/megatron/logs/log_2GPU.txt) 을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "sd91GOgtDimQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 0] (after 10 iterations) memory (MB) | allocated: 1907.2294921875 | max allocated: 10582.0205078125 | reserved: 10922.0 | max reserved: 10922.0\n",
      " iteration       10/     100 | consumed samples:           40 | elapsed time per iteration (ms): 820.3 | learning rate: 6.000E-05 | global batch size:     4 | lm loss: 1.050107E+01 | loss scale: 1.0 | grad norm: 6.424 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       20/     100 | consumed samples:           80 | elapsed time per iteration (ms): 464.1 | learning rate: 5.997E-05 | global batch size:     4 | lm loss: 9.977966E+00 | loss scale: 1.0 | grad norm: 2.653 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       30/     100 | consumed samples:          120 | elapsed time per iteration (ms): 470.5 | learning rate: 5.990E-05 | global batch size:     4 | lm loss: 9.543288E+00 | loss scale: 1.0 | grad norm: 2.567 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       40/     100 | consumed samples:          160 | elapsed time per iteration (ms): 470.3 | learning rate: 5.978E-05 | global batch size:     4 | lm loss: 9.067947E+00 | loss scale: 1.0 | grad norm: 2.567 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       50/     100 | consumed samples:          200 | elapsed time per iteration (ms): 468.2 | learning rate: 5.963E-05 | global batch size:     4 | lm loss: 8.768627E+00 | loss scale: 1.0 | grad norm: 2.372 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       60/     100 | consumed samples:          240 | elapsed time per iteration (ms): 473.1 | learning rate: 5.943E-05 | global batch size:     4 | lm loss: 8.349467E+00 | loss scale: 1.0 | grad norm: 2.383 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       70/     100 | consumed samples:          280 | elapsed time per iteration (ms): 471.1 | learning rate: 5.919E-05 | global batch size:     4 | lm loss: 8.092303E+00 | loss scale: 1.0 | grad norm: 2.753 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
      " iteration       80/     100 | consumed samples:          320 | elapsed time per iteration (ms): 473.6 | learning rate: 5.891E-05 | global batch size:     4 | lm loss: 7.885275E+00 | loss scale: 1.0 | grad norm: 1.932 | number of skipped iterations:   0 | number of nan iterations:   0 |\n"
     ]
    }
   ],
   "source": [
    "! grep iteration /dli/megatron/logs/log_2GPU.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPV-zqNHDimR"
   },
   "source": [
    "추출 로그에서 2개의 GPU를 사용하는 동안 1개의 GPU와 비교하여 훈련 성능을 확인합니다.\n",
    "\n",
    "` iteration      100/     100 | consumed samples:          400 | elapsed time per iteration (ms): 363.6 | learning rate: 5.822E-05 | global batch size:     4 | lm loss: 7.500983E+00 | loss scale: 1.0 | grad norm: 1.360 | number of skipped iterations:   0 | number of nan iterations:   0 |`\n",
    " \n",
    " \n",
    "소모된 샘플의 수와 해당 훈련 시간에 유의하십시오. 또한 이는 멀티 GPU 시스템에서 바람직한 특성인 거의 선형적인 증가를 보이고 있습니다.\n",
    "\n",
    "성능에 대해 강사님과 토론해 봅시다 여기서 가장 큰 변화는 같은 시간 동안 처리된 샘플의 수가 더 많다는 것입니다. 따라서 모델이 더 풍부한 데이터 표현을 학습하여 트레이닝을 가속화하는 데 도움이 됩니다.\n",
    "\n",
    "좋습니다. 다음으로 넘어가기 전에 이전 실행에서 생성된 불필요한 체크포인트를 삭제하여 디스크 공간을 확보하고 나머지 대화형 세션을 취소하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "iC86bfRPDimR"
   },
   "outputs": [],
   "source": [
    "# Clean the checkpoints\n",
    "! rm -rf /dli/megatron/checkpoints/*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYHfhiPODimS"
   },
   "source": [
    "## 2.3.3 모델 배포 시 고려 사항 \n",
    "\n",
    "텐서 또는 파이프라인 병렬 모드에서 이전 멀티-GPU 스크립트를 실행하려면`--tensor-model-parallel-size` 또는`--pipeline-model-parallel-size` 인자를 사용하여 분포를 구성할 수 있습니다. \n",
    "\n",
    "GPU 수에 해당하는 Megatron-LM 훈련의 월드 크기는 그대로 유지되며 데이터-병렬, 텐서-모델-병렬 및 파이프라인-모델-병렬은 구성에 따라 조정해야 합니다. \n",
    "\n",
    "```\n",
    "world size: 2, data-parallel-size: 1, tensor-model-parallel size: 2, pipeline-model-parallel size: 1\n",
    "or\n",
    "world size: 2, data-parallel-size: 1, tensor-model-parallel size: 1, pipeline-model-parallel size: 2\n",
    "\n",
    "```\n",
    "월드 크기는 데이터 병렬 크기, 텐서 모델 병렬 및 파이프라인 모델 병렬의 곱입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTFJiorHDimS"
   },
   "source": [
    "---\n",
    "<h2 style=\"color:green;\">축하합니다!</h2>\n",
    "\n",
    "GPU 클러스터에서 GPT-3를 사전 훈련해보았습니다! 훌륭합니다.<br>\n",
    "\n",
    "다음으로 넘어가기 전에 SLURM 대기열에서 실행 중이거나 대기 중인 작업이 없는지 확인해야 합니다. \n",
    "다음 셀을 실행하여 SLURM 작업 대기열을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "dknQ3tbgDimT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "                 7  slurmpar     bash    admin  R      27:17      1 slurmnode1\n",
      "                 8  slurmpar     bash    admin  R       3:03      1 slurmnode1\n"
     ]
    }
   ],
   "source": [
    "# Check the SLURM jobs queue \n",
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2g68E4azDimU"
   },
   "source": [
    "여전히 실행 중이거나 보류 중인 작업이 있는 경우 다음 셀을 실행하여 `scancel`  명령을 사용하여 모든 사용자의 작업을 취소합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Obl5vsCTDimU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n"
     ]
    }
   ],
   "source": [
    "# Cancel admin user jobs\n",
    "! scancel -u $USER\n",
    "\n",
    "# Check again the SLURM jobs queue (should be either empty, or the status TS column should be CG)\n",
    "! squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIgkRhMdDimU"
   },
   "source": [
    "다음으로 멀티 노드 분산 구성에 대한 GPT 언어 모델 훈련을 실행할 것입니다. [03_GPT_LM_pretrainings_multinodes.ipynb](03_GPT_LM_pretrainings_multinodes.ipynb)로 이동합니다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "02_GPT_LM_pretrainings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
